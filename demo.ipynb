{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZI-7IKtJYIIf"},"source":["\n","# ðŸ•ºðŸ•ºðŸ•º Follow Your Pose ðŸ’ƒðŸ’ƒðŸ’ƒ: \n","# Pose-Guided Text-to-Video Generation using Pose-Free Videos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1680855034941,"user":{"displayName":"yue ma","userId":"10565880864345925493"},"user_tz":-480},"id":"GPBJ9ZPNWofP","outputId":"08c669fd-6983-48ab-805f-31878714772c","vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@markdown Check type of GPU and VRAM available.\n","!nvidia-smi - -query-gpu = name, memory.total, memory.free - -format = csv, noheader\n","#make sure you are using Tesla T4, 15360 MiB, 15101 MiB\n"]},{"cell_type":"markdown","metadata":{"id":"JGTUagmtwwxo"},"source":["# ðŸ•ºðŸ•ºðŸ•º Install Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21760,"status":"ok","timestamp":1680855062851,"user":{"displayName":"yue ma","userId":"10565880864345925493"},"user_tz":-480},"id":"JmWCIBSnZP4l","outputId":"7cbd0308-8e11-4140-8bff-58d9368d4a13","vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["# @title  Environment Setup\n","!apt-get update\n","!apt install software-properties-common\n","!sudo dpkg --remove --force-remove-reinstreq python3-pip python3-setuptools python3-wheel\n","!apt-get install python3-pip\n","\n","!git clone https: // github.com/jiaxinlarhh/ict3104-team13-2023.git\n","\n","!git clone https: // github.com/open-mmlab/mmpose.git\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["# @title  Setup FollowYourPose & MMPose\n","\n","# FollowYourPose\n","!cd / content/ict3104-team13-2023\n","!export PYTHONPATH = /content/ict3104-team13-2023: $PYTHONPATH\n","!python - m pip install - q - U - -pre triton\n","!apt update\n","!python - m pip install - q diffusers == 0.11.1 torch == 1.13.1 transformers == 4.26.0 bitsandbytes == 0.35.4 imageio-ffmpeg xformers == 0.0.16 - -extra-index-url https: // download.pytorch.org/whl/cu113\n","\n","# MMPose\n","%cd / content/mmpose\n","!python3 - m pip install torch torchvision torchaudio - -index-url https: // download.pytorch.org/whl/cu118\n","# install MMEngine, MMCV and MMDetection using MIM\n","!python3 - m pip install - U openmim\n","!mim install mmengine\n","!mim install \"mmcv>=2.0.0\"\n","!mim install \"mmdet>=3.0.0\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title US T13-34 Upload Models into Hugging Face\n","\n","!python -m pip install -q transformers\n","!python -m pip install -q huggingface_hub\n","\n","from huggingface_hub import HfApi, HfFolder, notebook_login, create_repo\n","from ipywidgets import widgets, HBox, Layout\n","from IPython.display import display, HTML\n","import os\n","\n","html_code = \"<br/><br/><br/>\"  # Space HTML\n","\n","api_upload_token = \"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\"\n","# hf_api = HfApi()\n","# hf_folder = HfFolder()\n","# notebook_login() #Login to huggingface from colab\n","hf_api = HfApi(\n","    endpoint=\"https://huggingface.co\", # endpoint.\n","    token=api_upload_token, # Token is not persisted on the machine.\n",")\n","\n","# Creating repository_name_input UI\n","repository_name_input = widgets.Text(\n","    value='',  # Initial value of the input field\n","    placeholder='E.g TestModel (no whitespaces)',  # Placeholder text\n","    description='New repo name:',  # Label for the input field\n","    layout=widgets.Layout(width='30%')\n",")\n","\n","# Creating add_new_repository_button UI\n","add_new_repository_button = widgets.Button(\n","    description='Create new repository',  # Button label\n","    layout=Layout(width='150px')  # Adjust the width as needed\n",")\n","\n","# Creating Upload Button UI\n","upload_to_repo_button = widgets.Button(\n","    description='Upload',  # Button label\n","    layout=Layout(width='150px')  # Adjust the width as needed\n",")\n","\n","# Get a list of all checkpoints\n","checkpoint_directory = \"/content/ict3104-team13-2023/checkpoints\"\n","list_of_checkpoints = [folder for folder in os.listdir(checkpoint_directory) if os.path.isdir(os.path.join(checkpoint_directory, folder))]\n","\n","# Create a select checkpoint dropdown UI\n","checkpoint_dropdown = widgets.Dropdown(\n","    options=list_of_checkpoints,\n","    description='Select a checkpoint to upload to hugging face:'\n",")\n","\n","# Creating repository_name_input UI\n","repository_name_input = widgets.Text(\n","    value='',  # Initial value of the input field\n","    placeholder='E.g TestModel (no whitespaces)',  # Placeholder text\n","    description='New repo name:',  # Label for the input field\n","    layout=widgets.Layout(width='30%')\n",")\n","\n","# Creating repository_name_input UI\n","repository_upload_destination_input = widgets.Text(\n","    value='',  # Initial value of the input field\n","    placeholder='E.g TestModel (no whitespaces)',  # Placeholder text\n","    description='Enter repo name:',  # Label for the input field\n","    layout=widgets.Layout(width='30%')\n",")\n","\n","# On 'Create new repository button' click, a new repo will be created in hugging face account\n","def on_button_click(b):\n","    # Will create a repo once only need to change to a new repository name on each run of this cell\n","    repository_name = repository_name_input.value\n","    repo_id = hf_api.create_repo(repository_name)\n","\n","# Define a function to upload model to hugging face\n","def upload_click(b):\n","  # Path to model directory\n","  model_directory = \"/content/ict3104-team13-2023/checkpoints/\"\n","\n","  # Concatenate chosen checkpoint\n","  model_directory += checkpoint_dropdown.value\n","  hf_api.upload_folder(\n","    folder_path= model_directory,\n","    repo_id=\"3104FYPHuggingFace/\" + repository_upload_destination_input.value,\n","    repo_type=\"model\",\n","  )\n","\n","# Define a function to handle the dropdown value change\n","def on_dropdown_change(change):\n","    selected_folder = change.new\n","\n","# Attach the option change to checkpoint_dropdown\n","checkpoint_dropdown.observe(on_dropdown_change, names='value')\n","\n","# Attach the event handler to the button\n","add_new_repository_button.on_click(on_button_click)\n","upload_to_repo_button.on_click(upload_click)\n","\n","# Display the button\n","display(repository_name_input)\n","display(add_new_repository_button)\n","display(HTML(html_code))\n","display(repository_upload_destination_input)\n","display(checkpoint_dropdown)\n","display(upload_to_repo_button)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title US T13-35 Download Models from Hugging Face\n","\n","# from transformers import HfApi, HfFolder, logging, set_seed\n","from huggingface_hub import HfApi, HfFolder, notebook_login, create_repo, snapshot_download\n","from ipywidgets import widgets, HBox, Layout\n","from IPython.display import display, HTML\n","import os\n","import subprocess\n","\n","html_code = \"<br/><br/><br/>\"  # Space HTML\n","\n","api_upload_token = \"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\"\n","\n","hf_api = HfApi(\n","    endpoint=\"https://huggingface.co\", # endpoint.\n","    token=api_upload_token, # Token is not persisted on the machine.\n",")\n","\n","checkpoint_directory = \"/content/ict3104-team13-2023/checkpoints\"\n","list_of_checkpoints = [folder for folder in os.listdir(checkpoint_directory) if os.path.isdir(os.path.join(checkpoint_directory, folder))]\n","\n","# Create a select checkpoint dropdown UI\n","checkpoint_dropdown = widgets.Dropdown(\n","    options=list_of_checkpoints,\n","    description='Select a checkpoint to upload to hugging face:'\n",")\n","\n","# Creating add_new_repository_button UI\n","download_from_repository_button = widgets.Button(\n","    description='Download from repository',  # Button label\n","    layout=Layout(width='150px')  # Adjust the width as needed\n",")\n","\n","# On 'download_from_repository_button' click, model in that repo will be downloaded\n","def on_button_click(b):\n","    # snapshot_download(repo_id=\"3104FYPHuggingFace/TestModel\")\n","    try:\n","        # Run the Git LFS clone command\n","        subprocess.run([\"git\", \"lfs\", \"clone\", \"https://huggingface.co/3104FYPHuggingFace/TestModel\", os.getcwd()], check=True)\n","        print(f\"Successfully cloned the model to {os.getcwd()}\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"Failed to clone the model: {e}\")\n","\n","# Define a function to handle the dropdown value change\n","def on_dropdown_change(change):\n","    print(checkpoint_directory)\n","    new_directory = checkpoint_directory + \"/\" + checkpoint_dropdown.value\n","    if os.path.isdir(new_directory):\n","        os.chdir(new_directory)\n","        # Now, the current working directory is changed to selected_folder\n","        print(f\"Changed directory to: {os.getcwd()}\")\n","    else:\n","        print(f\"The selected folder does not exist or is not a directory.\")\n","\n","\n","download_from_repository_button.on_click(on_button_click)\n","# Attach the option change to checkpoint_dropdown\n","checkpoint_dropdown.observe(on_dropdown_change, names='value')\n","\n","# Display the button\n","display(download_from_repository_button)\n","display(checkpoint_dropdown)"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º Data Exploration"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title US T13-31 Select Dataset for Training / Testing \n","\n","import os\n","import ipywidgets as widgets\n","from IPython.display import display\n","\n","data_folder = '/content/ict3104-team13-2023/data_folder'\n","\n","# Define functions to handle button clicks\n","def choose_training_folder(b):\n","    training_subfolder = training_dropdown.value\n","    print(f'Selected training subfolder: {training_subfolder}')\n","\n","def choose_testing_folder(b):\n","    testing_subfolder = testing_dropdown.value\n","    print(f'Selected testing subfolder: {testing_subfolder}')\n","\n","# List subfolders in the data folder\n","subfolders = [f for f in os.listdir(data_folder) if os.path.isdir(os.path.join(data_folder, f))]\n","\n","# Create dropdown widgets for training and testing\n","training_dropdown = widgets.Dropdown(\n","    options=subfolders,\n","    description='Folder:',\n",")\n","testing_dropdown = widgets.Dropdown(\n","    options=subfolders,\n","    description='Folder:',\n",")\n","\n","# Create buttons to trigger the folder selection\n","train_button = widgets.Button(description=\"Training\")\n","test_button = widgets.Button(description=\"Testing\")\n","\n","# Assign the functions to be called when the buttons are clicked\n","train_button.on_click(choose_training_folder)\n","test_button.on_click(choose_testing_folder)\n","\n","# Display the widgets\n","display(training_dropdown, train_button)\n","display(testing_dropdown, test_button)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@title US T13-3 Input files subfolders\n","\n","import os\n","\n","main_folder = '/content/ict3104-team13-2023/data_folder'\n","\n","if not os.path.exists(main_folder):\n","    os.mkdir(main_folder)\n","\n","subfolders = ['stickman', 'others']\n","\n","for subfolder in subfolders:\n","    subfolder_path = os.path.join(main_folder, subfolder)\n","\n","    if not os.path.exists(subfolder_path):\n","        os.mkdir(subfolder_path)\n","        print(f\"Created subfolder '{subfolder_path}'\")"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title US T13-17 Testing Subfolders\n","\n","import os\n","\n","main_folder = '/content/ict3104-team13-2023/data_folder/testing'\n","\n","if not os.path.exists(main_folder):\n","    os.mkdir(main_folder)\n","\n","subfolders = ['stickman']\n","\n","for subfolder in subfolders:\n","    subfolder_path = os.path.join(main_folder, subfolder)\n","\n","    if not os.path.exists(subfolder_path):\n","        os.mkdir(subfolder_path)\n","        print(f\"Created subfolder '{subfolder_path}'\")"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@title  US T13-4 Load Video (Edited by US T13-33)\n","\n","!apt-get install ffmpeg\n","\n","import ipywidgets as widgets\n","import os, cv2\n","from os import listdir\n","from google.colab.patches import cv2_imshow\n","from IPython.display import HTML, Video, display, clear_output, Image\n","from base64 import b64encode\n","import base64\n","\n","input_folder = '/content/ict3104-team13-2023/data_folder/stickman/'\n","output_folder = '/content/ict3104-team13-2023/data_folder/stickman/converted/'\n","\n","if not os.path.exists(output_folder):\n","    os.makedirs(output_folder)\n","\n","for filename in os.listdir(input_folder):\n","    if filename.endswith(\".mp4\"):\n","        input_file = os.path.join(input_folder, filename)\n","        output_file = os.path.join(output_folder, filename)\n","        cmd = f'ffmpeg -i \"{input_file}\" -vcodec libx264 \"{output_file}\"'\n","        os.system(cmd)\n","\n","skeleton_list = []\n","charades_list = []\n","output_list = []\n","\n","skeleton_directory = 'data_folder/stickman/converted'\n","charades_directory = 'charades'\n","output_directory = 'data_folder/inference_result'\n","\n","current_directory = os.getcwd()\n","\n","# store video names in list\n","for file in os.listdir(os.path.join(current_directory, skeleton_directory)):\n","  if file[0] != \".\":\n","    skeleton_list.append(file)\n","for file in os.listdir(os.path.join(current_directory, charades_directory)):\n","  if file[0] != \".\":\n","    charades_list.append(file)\n","for file in os.listdir(os.path.join(current_directory, output_directory)):\n","  if file[0] != \".\":\n","    output_list.append(file)\n","\n","# Create labels for each dropdown\n","skeleton_label = widgets.Label(value=\"Skeleton:\")\n","charades_label = widgets.Label(value=\"Charades:\")\n","output_label = widgets.Label(value=\"Output:\")\n","\n","# show vid name in list as dropdown\n","skeleton_dropdown = widgets.Dropdown(options=skeleton_list, value=None)\n","charades_dropdown = widgets.Dropdown(options=charades_list, value=None)\n","output_dropdown = widgets.Dropdown(options=output_list, value=None)\n","\n","# Group each label and dropdown together using an HBox\n","skeleton_box = widgets.HBox([skeleton_label, skeleton_dropdown])\n","charades_box = widgets.HBox([charades_label, charades_dropdown])\n","output_box = widgets.HBox([output_label, output_dropdown])\n","\n","skeleton_output = widgets.Output()\n","charades_output = widgets.Output()\n","output_output = widgets.Output()\n","display(skeleton_box, charades_box, output_box, skeleton_output, charades_output, output_output)\n","\n","# UI functions\n","def on_dropdown_change(change):\n","    dropdown = change['owner']\n","\n","    if dropdown is skeleton_dropdown:\n","      display_media(\"skeleton\", skeleton_directory, change['new'])\n","    elif dropdown is charades_dropdown:\n","      display_media(\"charades\", charades_directory, change['new'])\n","    elif dropdown is output_dropdown:\n","      display_media(\"output\", output_directory, change['new'])\n","\n","def display_media(typeToShow, directory, value):\n","    video_path = os.path.join(current_directory, directory + '/' + value)\n","    if typeToShow == \"skeleton\":\n","      with skeleton_output:\n","          skeleton_mp4 = open(video_path,'rb').read()\n","          skeleton_data_url = \"data:video/mp4;base64,\" + b64encode(skeleton_mp4).decode()\n","          if skeleton_mp4 and skeleton_data_url:\n","            video_html = f'<h1>Skeleton:</h1><video width=\"200\" height=\"200\" controls><source src=\"{skeleton_data_url}\" type=\"video/mp4\"></video>'\n","            clear_output()\n","            display(HTML(video_html))\n","          else:\n","            print(\"Cannot open chosen charades video\")\n","    if typeToShow == \"charades\":\n","        with charades_output:\n","            charades_mp4 = open(video_path,'rb').read()\n","            charades_data_url = \"data:video/mp4;base64,\" + b64encode(charades_mp4).decode()\n","            if charades_mp4 and charades_data_url:\n","              video_html = f'<h1>Charades:</h1><video width=\"200\" height=\"200\" controls><source src=\"{charades_data_url}\" type=\"video/mp4\"></video>'\n","              clear_output()\n","              display(HTML(video_html))\n","            else:\n","              print(\"Cannot open chosen charades video\")\n","    if typeToShow == \"output\":\n","      with output_output:\n","        clear_output()\n","        display(HTML(\"<h1>Generated Gif:</h1>\"))\n","        display(Image(filename=video_path))\n","\n","\n","skeleton_dropdown.observe(on_dropdown_change, names='value')\n","charades_dropdown.observe(on_dropdown_change, names='value')\n","output_dropdown.observe(on_dropdown_change, names='value')"]},{"cell_type":"markdown","metadata":{"id":"Kbx46ZU6znrs"},"source":["# ðŸ•ºðŸ•ºðŸ•º Inference"]},{"cell_type":"markdown","metadata":{"id":"6GW8-Xz8zwnE"},"source":["Due to memory of GPU, we recommend set video_length=8 in ./config/pose_sample.yaml for running successfully. \n","\n","Meanwhile, we should keep the skeleton frame length(./followyourpose/pipelines/pipeline_followyourpose.py:422 ) equal with video_length"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["%cd /content/FollowYourPose\n","!pwd\n","!TORCH_DISTRIBUTED_DEBUG=DETAIL accelerate launch txt2video.py --config=\"configs/pose_sample.yaml\"  --skeleton_path=\"./pose_example/vis_ikun_pose2.mov\""]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# @title US T13-16 Select skeleton video and perform inference (integrated with US T13-6 and T13-28)\n","import os\n","from ipywidgets import interact, widgets\n","from IPython.display import display, HTML, Image, clear_output\n","from functools import partial\n","import subprocess\n","import yaml\n","\n","\n","# Declare file_dropdown as a global variable\n","file_dropdown = None\n","stickman_directory = '/content/ict3104-team13-2023/data_folder/stickman'\n","input_path = \"\"\n","\n","\n","\n","\n","def display_file_dropdown():\n","    # Define the directory path\n","\n","    # Get a list of files in the directory\n","    files = os.listdir(stickman_directory)\n","\n","    # Create a dropdown widget with the default value set to None\n","    global file_dropdown\n","    file_dropdown = widgets.Dropdown(\n","        options=[''] + files,\n","        description='Select File:',\n","        disabled=False,\n","        value=None,\n","    )\n","\n","\n","\n","    # Create an output widget to display the selected file\n","    output = widgets.Output()\n","\n","    # Define a function to handle the dropdown selection\n","    def on_file_select(change):\n","        selected_file = change.new\n","        with output:\n","            clear_output()\n","            # Display the selected MP4 file\n","            if selected_file:\n","                print(f\"Selected File: {selected_file}\")\n","            else:\n","                print(\"No file selected\")\n","\n","    # Attach the function to the dropdown's change event\n","    file_dropdown.observe(on_file_select, names='value')\n","\n","    # Display the dropdown and the output widget\n","    display(file_dropdown)\n","    display(output)\n","\n","# method to add user's prompt into pose_sample.yaml\n","def insert_prompt_input_into_config(prompt):\n","\n","  # Load the YAML file\n","  with open('/content/ict3104-team13-2023/configs/pose_sample.yaml', 'r') as file:\n","      config = yaml.safe_load(file)\n","\n","  # Access the 'prompts' section\n","  config['validation_data']['prompts'] = [prompt]\n","\n","  # Save the modified configuration back to the file\n","  with open('/content/ict3104-team13-2023/configs/pose_sample.yaml', 'w') as file:\n","      yaml.dump(config, file, default_flow_style=False)\n","\n","\n","def on_button_click(b):\n","    # Perform an action when the button is clicked\n","    insert_prompt_input_into_config(prompt_input.value)\n","    selected_file = file_dropdown.value\n","    if selected_file:\n","        global input_path\n","        input_path = os.path.join(stickman_directory, selected_file)\n","\n","        !TORCH_DISTRIBUTED_DEBUG=DETAIL accelerate launch txt2video.py --config=\"configs/pose_sample.yaml\"  --skeleton_path=\"{input_path}\"\n","\n","def user_input():\n","    # Call the function to display the dropdown\n","    display_file_dropdown()\n","\n","    global prompt_input\n","    # Show input to accept user prompt\n","    prompt_input = widgets.Text(\n","      value='',  # Initial value\n","      placeholder='Enter prompt...',  # Placeholder text\n","      description='Prompt Input: ',  # Label for the input\n","    )\n","\n","    # Create a button widget\n","    button = widgets.Button(description=\"Confirm\")\n","    button.on_click(on_button_click)\n","\n","    # Display the button\n","    display(prompt_input, button)\n","\n","# Call the user_input function\n","user_input()"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["# @title US T13-7 Function to combine gif\n","\n","import os\n","from moviepy.editor import VideoFileClip, clips_array\n","\n","# Function to combine an MP4 video with a matching skeleton video in the same directory\n","def combine_and_create_gif(mp4_path):\n","    # Get the base name of the MP4 file (including the extension)\n","    file_name_with_extension = os.path.basename(mp4_path)\n","\n","    # Split the file name from the extension\n","    file_name, file_extension = os.path.splitext(file_name_with_extension)\n","\n","    # Directory containing the skeleton videos\n","    skeleton_folder = \"/content/ict3104-team13-2023/data_folder/stickman\"\n","\n","    # Search for a matching skeleton video in the skeleton folder\n","    skeleton_video_path = os.path.join(skeleton_folder, f\"{file_name}.mp4\")\n","\n","    if os.path.isfile(skeleton_video_path):\n","        # Loading the MP4 and skeleton videos\n","        mp4_video = VideoFileClip(mp4_path)\n","        skeleton_video = VideoFileClip(skeleton_video_path)\n","\n","        # Determine the minimum duration of the two videos\n","        common_duration = min(mp4_video.duration, skeleton_video.duration)\n","\n","        # Trim both videos to the common duration\n","        mp4_video = mp4_video.subclip(0, common_duration)\n","        skeleton_video = skeleton_video.subclip(0, common_duration)\n","\n","        # Directory for the output GIF\n","        output_directory = \"/content/ict3104-team13-2023/data_folder/inference_result/\"\n","        output_gif_path = os.path.join(output_directory, f\"{file_name}.gif\")\n","\n","        # Ensure the output directory exists, or create it if it doesn't\n","        os.makedirs(output_directory, exist_ok=True)\n","\n","        # Resize both videos to have the same width and height\n","        min_width = 512\n","        min_height = 512\n","        mp4_video = mp4_video.resize((min_width, min_height))\n","        skeleton_video = skeleton_video.resize((min_width, min_height))\n","\n","        # Combine the videos side by side\n","        result = clips_array([[skeleton_video, mp4_video]])\n","\n","        # Write as GIF for display\n","        result.write_gif(output_gif_path, fps=30)\n","\n","    else:\n","        print(f\"No matching skeleton video found for {file_name}.\")\n","        return\n","\n","# Directory containing the input videos\n","input_directory = \"/content/ict3104-team13-2023/data_folder/inference\"\n","\n","# Directory containing skeleton videos\n","skeleton_directory = \"/content/ict3104-team13-2023/data_folder/stickman\"\n","\n","# Function to process all videos in the input directory\n","def process_all_videos(input_directory, skeleton_directory):\n","    # Get a list of all video files in the input directory\n","    video_files = [f for f in os.listdir(input_directory) if f.endswith(\".gif\")]\n","\n","    for video_file in video_files:\n","        video_path = os.path.join(input_directory, video_file)\n","        combine_and_create_gif(video_path)\n","\n","# Process all videos in the input directory\n","process_all_videos(input_directory, skeleton_directory)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title Display inferenced videos with captions\n","# show side by side gif\n","from IPython.display import HTML, display, Image\n","import yaml\n","import os\n","import ipywidgets as widgets\n","from IPython.display import clear_output\n","\n","# Function to display inference result\n","def display_inference_result(result_path, caption):\n","\n","    if os.path.isfile(result_path):\n","        center_div = HTML('<div style=\"display: flex; justify-content: center;\">')\n","\n","        clear_output(wait=True)  # Clear any previous output\n","        display(center_div)\n","        display(Image(filename=result_path))\n","        display(HTML(f'<p style=\"text-align:center; font-size:16px;\">{caption}</p>'))\n","    else:\n","        print(\"GIF file not found in the specified directory.\")\n","\n","# Function to get the list of output GIF files in the specified directory\n","def get_output_files_list(output_directory):\n","    output_files = [f for f in os.listdir(output_directory) if f.endswith(\".gif\")]\n","    return output_files\n","\n","# Dropdown widget to select the output file\n","output_directory = \"/content/ict3104-team13-2023/data_folder/inference_result\"\n","output_files = get_output_files_list(output_directory)\n","\n","output_dropdown = widgets.Dropdown(\n","    options=output_files,\n","    description=\"Select Output File:\",\n","    disabled=False,\n",")\n","\n","# Submit button\n","submit_button = widgets.Button(description=\"Submit\")\n","\n","# Output widget to capture the output\n","output_widget = widgets.Output()\n","\n","# Function to handle dropdown selection and submit\n","def on_submit_button_clicked(b):\n","    with output_widget:\n","        clear_output(wait=True)\n","        result_path = os.path.join(output_directory, output_dropdown.value)\n","        prompt = get_prompt_from_yaml()\n","        display_inference_result(result_path, prompt)\n","\n","# Attach the button click event handler\n","submit_button.on_click(on_submit_button_clicked)\n","\n","# Display the dropdown and the submit button\n","widgets.VBox([output_dropdown, submit_button, output_widget])\n"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º Training"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@title  User Story T13-8: Select subfolder from dataset folder\n","import ipywidgets as widgets\n","import os, cv2\n","from os import listdir\n","from ipywidgets import Dropdown, interact\n","\n","data_directory = \"./dataset_folder\"\n","directory_dict = {}\n","\n","# get subfolders as key and list of files as value in dict\n","for root, subfolders, files in os.walk(data_directory):\n","    # Skip the root directory itself\n","    if root == data_directory:\n","        continue\n","\n","    subfolder_name = os.path.relpath(root, data_directory)\n","\n","    if \".ipynb\" in subfolder_name:\n","      continue\n","    # Create a list of file names in the subfolder\n","    file_names = [file for file in files]\n","    # Add the subfolder and its file names to the dictionary\n","    directory_dict[subfolder_name] = file_names\n","#print(directory_dict)\n","\n","\n","# dropdown UI\n","subfolder_choices = Dropdown(options =directory_dict.keys())\n","subfolder_files = Dropdown()\n","button = widgets.Button(description=\"Select dataset\")\n","\n","\n","@interact(subfolder = subfolder_choices, dataset = subfolder_files)\n","def print_city(subfolder, dataset):\n","    subfolder_files.options = directory_dict[subfolder]\n","\n","# UI\n","display(button)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@title  User Story T13-6\n","import ipywidgets as widgets\n","import os, cv2\n","import subprocess\n","import yaml\n","from os import listdir\n","from google.colab.patches import cv2_imshow\n","from IPython.display import HTML, clear_output\n","from base64 import b64encode\n","\n","\n","# Define and Instantiate variables\n","charades_data_url = None\n","charades_video_path = \"./charades\"\n","charades_video_list = []\n","chosen_charades_video = None\n","\n","# Store names of charades video in a list\n","for file in os.listdir(charades_video_path):\n","  charades_video_list.append(file)\n","\n","# Show input to accept user prompt\n","prompt_input = widgets.Text(\n","    value='',  # Initial value\n","    placeholder='Enter prompt...',  # Placeholder text\n","    description='Prompt Input: ',  # Label for the input\n",")\n","\n","# Add names of charades video as dropdown options\n","charades_videos_dropdown = widgets.Dropdown(options=charades_video_list, value=None)\n","\n","# UI to show after running this cell\n","choose_charades_video_button = widgets.Button(description=\"Choose Video\")\n","chosen_video_output = widgets.Output()\n","\n","# Display all UI\n","display(prompt_input, charades_videos_dropdown, choose_charades_video_button, chosen_video_output)\n","\n","# method to add user's prompt into pose_sample.yaml\n","def insert_prompt_input_into_config(prompt):\n","\n","  # Load the YAML file\n","  with open('./configs/pose_sample.yaml', 'r') as file:\n","      config = yaml.safe_load(file)\n","\n","  # Access the 'prompts' section\n","  config['validation_data']['prompts'] = [prompt]\n","\n","\n","  # Save the modified configuration back to the file\n","  with open('./configs/pose_sample.yaml', 'w') as file:\n","      yaml.dump(config, file, default_flow_style=False)\n","\n","def generate_gif():\n","  # Change directory to /content/ict3104-team13-2023\n","  os.chdir('/content/ict3104-team13-2023')\n","\n","  # Print the current working directory\n","  print(os.getcwd())\n","\n","  # Set the TORCH_DISTRIBUTED_DEBUG environment variable and launch txt2video.py\n","  subprocess.run(['accelerate', 'launch', 'txt2video.py', '--config=configs/pose_sample.yaml', '--skeleton_path=./pose_example/vis_ikun_pose2.mov'])\n","\n","#\n","def set_charades_video_variables(charades_video_name):\n","  if charades_video_name is not None:\n","    # print(\"Have something\")\n","    pass\n","  with chosen_video_output:\n","        charades_mp4 = open(charades_video_path +'/'+ charades_video_name,'rb').read()\n","        charades_data_url = \"data:video/mp4;base64,\" + b64encode(charades_mp4).decode()\n","        if charades_mp4 and charades_data_url:\n","          video_html = f'<video controls><source src=\"{charades_data_url}\" type=\"video/mp4\"></video>'\n","          # Clear previous output\n","          clear_output()\n","          display(HTML(video_html))\n","        else:\n","          print(\"Cannot open chosen charades video\")\n","\n","# OnClick function for 'Choose Video' button\n","def on_choose_charades_video_button_clicked(b):\n","    pass\n","\n","# OnChange function for dropdown\n","def on_charades_videos_dropdown_change(change):\n","    if change['name'] == 'value' and change['new']:\n","        chosen_charades_video = change['new']\n","        selected_option = change['new']\n","        # print(f\"Selected option: {selected_option}\")\n","        set_charades_video_variables(selected_option)\n","\n","# On Prompt Input 'enter' key press\n","def on_prompt_input_enter_pressed(change):\n","      # print(\"Enter pressed with text:\", prompt_input.value)\n","      insert_prompt_input_into_config(prompt_input.value)\n","      generate_gif()\n","\n","# Attach event functions to UI\n","prompt_input.on_submit(on_prompt_input_enter_pressed)\n","charades_videos_dropdown.observe(on_charades_videos_dropdown_change, names='value')\n","choose_charades_video_button.on_click(on_choose_charades_video_button_clicked)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title  User Story T13-10 (to be removed)\n","import ipywidgets as widgets\n","from IPython.display import display\n","\n","model_name_input = widgets.Text(\n","    placeholder='Enter Model Name',\n","    description='Model Name:',\n",")\n","\n","enter_button = widgets.Button(\n","    description='Enter',\n","    button_style='primary', \n",")\n","\n","# add to the model when its out\n","def handle_enter_button_click(b):\n","    model_name = model_name_input.value\n","    print(f'Done')\n","    \n","enter_button.on_click(handle_enter_button_click)\n","display(model_name_input, enter_button)"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#Implement progress bar here "]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title US T13-21 Save test result to result folder"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º MMPose"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title Environment Setup\n","!update-alternatives --install /usr/local/bin/python3 python3 /usr/bin/python3.8 2\n","!update-alternatives --install /usr/local/bin/python3 python3 /usr/bin/python3.9 1\n","!python --version\n","!apt-get update\n","!apt install software-properties-common\n","!sudo dpkg --remove --force-remove-reinstreq python3-pip python3-setuptools python3-wheel\n","!apt-get install python3-pip\n","\n","%cd /content\n","\n","# forked michael's mmpose because project needed to change some of the mmpose code\n","!git clone https://github.com/micdiary/mmpose.git\n","\n","#MMPose\n","%cd /content/mmpose\n","!python3 -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","# install MMEngine, MMCV and MMDetection using MIM\n","!python3 -m pip install -U openmim\n","!mim install mmengine\n","!mim install \"mmcv>=2.0.0\"\n","!mim install \"mmdet>=3.0.0\"\n","\n","!python3 -m pip install -r requirements.txt\n","!python3 -m pip install -v -e .\n","\n","!python3 -m pip install setuptools==68.1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title Check MMpose\n","\n","%cd /content/mmpose/\n","\n","# Check Pytorch installation\n","import torch, torchvision\n","\n","print('torch version:', torch.__version__, torch.cuda.is_available())\n","print('torchvision version:', torchvision.__version__)\n","\n","# Check MMPose installation\n","import mmpose\n","\n","print('mmpose version:', mmpose.__version__)\n","\n","# Check mmcv installation\n","from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n","\n","print('cuda version:', get_compiling_cuda_version())\n","print('compiler information:', get_compiler_version())"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title Inference with MMPOSE\n","# run inference on ALL videos in the charades folder\n","import os\n","\n","%cd /content/mmpose\n","\n","charades_video_path = \"/content/ict3104-team13-2023/charades/\"\n","\n","# List all the MP4 files in the specified directory\n","mp4_files = [f for f in os.listdir(charades_video_path) if f.endswith('.mp4')]\n","\n","\n","# Iterate through the MP4 files and run the script for each one\n","for mp4_file in mp4_files:\n","    input_path = os.path.join(charades_video_path, mp4_file)\n","    output_folder = f\"/content/ict3104-team13-2023/data_folder/stickman/\"\n","\n","    !python demo/topdown_demo_with_mmdet.py \\\n","    demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py \\\n","    https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n","    configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-256x192.py \\\n","    https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth \\\n","    --input {input_path} \\\n","    --output-root {output_folder}"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title Inference with MMPOSE (1 video)\n","# run inference on 1 video\n","import os\n","\n","%cd /content/mmpose\n","\n","charades_video_path = \"/content/ict3104-team13-2023/charades/52CKM.mp4\"\n","\n","output_folder = f\"/content/ict3104-team13-2023/data_folder/stickman3/\"\n","\n","!python demo/topdown_demo_with_mmdet.py \\\n","demo/mmdetection_cfg/faster_rcnn_r50_fpn_1class.py \\\n","https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n","configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-256x192.py \\\n","https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth \\\n","--input {charades_video_path} \\\n","--output-root {output_folder}"]},{"cell_type":"markdown","metadata":{},"source":["After conducting spam testing, we discovered that the first library we tested was superior to the other three libraries due to their outdated versions. Therefore, we will revert to using the first library, as it provides the desired skeleton result."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title  US T13-30\n","\n","import os\n","import tempfile\n","from base64 import b64encode\n","import ipywidgets as widgets\n","from moviepy.editor import VideoFileClip\n","from IPython.display import HTML, display, clear_output\n","\n","stickman_directory = '/content/ict3104-team13-2023/data_folder/stickman'\n","\n","output_directory = tempfile.mkdtemp()\n","converted_videos = []\n","\n","for video_file in os.listdir(stickman_directory):\n","    if video_file.endswith('.mp4'):\n","        video_path = os.path.join(stickman_directory, video_file)\n","        output_path = os.path.join(output_directory, os.path.splitext(video_file)[0] + '_h264.mp4')\n","\n","        clip = VideoFileClip(video_path)\n","        clip.write_videofile(output_path, codec='libx264', logger=None)\n","\n","        converted_videos.append(output_path)\n","        print(f\"Done converting {video_file}\")\n","\n","stickman_files = [f for f in os.listdir(output_directory) if f.endswith('_h264.mp4')]\n","\n","stickman_dropdown = widgets.Dropdown(\n","    options=stickman_files,\n","    description='Select Video:'\n",")\n","\n","output = widgets.Output()\n","\n","def display_selected_video(change):\n","    with output:\n","      clear_output()\n","      selected_video = change.new\n","      video_path = os.path.join(output_directory, selected_video)\n","\n","      with open(video_path, 'rb') as f:\n","          data = f.read()\n","          data_url = \"data:video/mp4;base64,\" + b64encode(data).decode()\n","          display(HTML(f\"\"\"\n","              <video controls autoplay>\n","                  <source src=\"{data_url}\" type=\"video/mp4\">\n","              </video>\n","          \"\"\"))\n","\n","stickman_dropdown.observe(display_selected_video, names='value')\n","display(stickman_dropdown)\n","display(output)"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º FID Scores"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#setup fid\n","!pip install pytorch-fid\n","!pip install ffmpeg\n","!pip install scipy==1.11.1"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","import os, sys, subprocess, re, shutil\n","from PIL import Image\n","from pathlib import Path\n","\n","fid_score_list = []\n","file_name_list = []\n","# Function to split video into frames\n","def split_video_into_frames(video_path, output_dir, restrict_frames):\n","    if restrict_frames:\n","      os.system(f\"ffmpeg -i {video_path} -vf 'select=lt(n\\\\,{restrict_frames})' {output_dir}%04d.png\")\n","    else:\n","      os.system(f\"ffmpeg -i {video_path} {output_dir}%04d.png\")\n","\n","# here for now but can remove if t13-32 is compiled\n","input_directory = \"/content/ict3104-team13-2023/data_folder/inference\"\n","stickman_without_background_dir = \"/content/ict3104-team13-2023/data_folder/stickman_without_background\"\n","##########################################################################################################\n","animation_gifs = os.listdir(input_directory)\n","stickman_mp4s = os.listdir(stickman_without_background_dir)\n","\n","# Output directories for frames\n","skeleton_frames_dir = \"/content/ict3104-team13-2023/data_folder/fid_skeleton_frames/\"\n","original_frames_dir = \"/content/ict3104-team13-2023/data_folder/fid_gif_frames/\"\n","\n","for animation, stickman in tqdm(zip(animation_gifs, stickman_mp4s),\n","                   total=len(os.listdir(input_directory)),\n","                   desc = \"Loading bar graph\"):\n","#for animation, stickman  in zip(animation_gifs, stickman_mp4s):\n","    # get file name\n","    name, filetype = animation.split(\".\")\n","    file_name_list.append(name)\n","    # The directory exists and is not empty, remove its contents\n","    shutil.rmtree(skeleton_frames_dir)\n","    shutil.rmtree(original_frames_dir)\n","\n","    os.makedirs(skeleton_frames_dir)\n","    os.makedirs(original_frames_dir)\n","\n","    split_video_into_frames(os.path.join(input_directory, animation), original_frames_dir, None)\n","    og_frame_path =  Path(original_frames_dir)\n","    files = [file for file in og_frame_path.iterdir() if file.is_file()]\n","    file_count = len(files)\n","    split_video_into_frames(os.path.join(stickman_without_background_dir, stickman), skeleton_frames_dir, file_count)\n","\n","    cmd = \"python -m pytorch_fid \"+skeleton_frames_dir+\" \"+original_frames_dir\n","    # Run the command and capture output\n","    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","    stdout, stderr = process.communicate()\n","\n","    # Print the standard output\n","    output_text = stdout.decode()\n","    fid_match = re.search(r'FID:\\s+([\\d.]+)', output_text)\n","    if fid_match:\n","        fid_score = float(fid_match.group(1))\n","        fid_score_list.append(fid_score)\n","    else:\n","        print(\"FID score not found in the output\")\n","\n","\n","plt.bar(file_name_list, fid_score_list, label=\"FID Scores\", color='b')\n","plt.xlabel(\"File names\")\n","plt.ylabel(\"FID Scores\")\n","plt.title(\"FID scores of files in directory\")\n","plt.legend()\n","plt.xticks(rotation=45)\n","plt.show()\n","\n","\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOyNNhRT8BBHJeqGAp6TaSp","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
