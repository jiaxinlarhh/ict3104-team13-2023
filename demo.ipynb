{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZI-7IKtJYIIf"},"source":["\n","# ðŸ•ºðŸ•ºðŸ•º Follow Your Pose ðŸ’ƒðŸ’ƒðŸ’ƒ: \n","# Pose-Guided Text-to-Video Generation using Pose-Free Videos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1680855034941,"user":{"displayName":"yue ma","userId":"10565880864345925493"},"user_tz":-480},"id":"GPBJ9ZPNWofP","outputId":"08c669fd-6983-48ab-805f-31878714772c","vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@markdown Check type of GPU and VRAM available.\n","!nvidia-smi - -query-gpu = name, memory.total, memory.free - -format = csv, noheader\n","#make sure you are using Tesla T4, 15360 MiB, 15101 MiB\n"]},{"cell_type":"markdown","metadata":{"id":"JGTUagmtwwxo"},"source":["# ðŸ•ºðŸ•ºðŸ•º Install Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21760,"status":"ok","timestamp":1680855062851,"user":{"displayName":"yue ma","userId":"10565880864345925493"},"user_tz":-480},"id":"JmWCIBSnZP4l","outputId":"7cbd0308-8e11-4140-8bff-58d9368d4a13","vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["# @title  Environment Setup\n","!apt-get update\n","!apt install software-properties-common\n","!sudo dpkg --remove --force-remove-reinstreq python3-pip python3-setuptools python3-wheel\n","!apt-get install python3-pip\n","\n","!git clone https: // github.com/jiaxinlarhh/ict3104-team13-2023.git\n","\n","!git clone https: // github.com/open-mmlab/mmpose.git\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["# @title  Setup FollowYourPose & MMPose\n","\n","# FollowYourPose\n","!cd / content/ict3104-team13-2023\n","!export PYTHONPATH = /content/ict3104-team13-2023: $PYTHONPATH\n","!python - m pip install - q - U - -pre triton\n","!apt update\n","!python - m pip install - q diffusers == 0.11.1 torch == 1.13.1 transformers == 4.26.0 bitsandbytes == 0.35.4 imageio-ffmpeg xformers == 0.0.16 - -extra-index-url https: // download.pytorch.org/whl/cu113\n","\n","# MMPose\n","%cd / content/mmpose\n","!python3 - m pip install torch torchvision torchaudio - -index-url https: // download.pytorch.org/whl/cu118\n","# install MMEngine, MMCV and MMDetection using MIM\n","!python3 - m pip install - U openmim\n","!mim install mmengine\n","!mim install \"mmcv>=2.0.0\"\n","!mim install \"mmdet>=3.0.0\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title US T13-34 Upload Models into Hugging Face\n","\n","!python -m pip install -q transformers\n","!python -m pip install -q huggingface_hub\n","\n","from huggingface_hub import HfApi, HfFolder, notebook_login, create_repo\n","from ipywidgets import widgets, HBox, Layout\n","from IPython.display import display, HTML\n","import os\n","\n","html_code = \"<br/><br/><br/>\"  # Space HTML\n","\n","api_upload_token = \"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\"\n","# hf_api = HfApi()\n","# hf_folder = HfFolder()\n","# notebook_login() #Login to huggingface from colab\n","hf_api = HfApi(\n","    endpoint=\"https://huggingface.co\", # endpoint.\n","    token=api_upload_token, # Token is not persisted on the machine.\n",")\n","\n","# Creating repository_name_input UI\n","repository_name_input = widgets.Text(\n","    value='',  # Initial value of the input field\n","    placeholder='E.g TestModel (no whitespaces)',  # Placeholder text\n","    description='New repo name:',  # Label for the input field\n","    layout=widgets.Layout(width='30%')\n",")\n","\n","# Creating add_new_repository_button UI\n","add_new_repository_button = widgets.Button(\n","    description='Create new repository',  # Button label\n","    layout=Layout(width='150px')  # Adjust the width as needed\n",")\n","\n","# Creating Upload Button UI\n","upload_to_repo_button = widgets.Button(\n","    description='Upload',  # Button label\n","    layout=Layout(width='150px')  # Adjust the width as needed\n",")\n","\n","# Get a list of all checkpoints\n","checkpoint_directory = \"/content/ict3104-team13-2023/checkpoints\"\n","list_of_checkpoints = [folder for folder in os.listdir(checkpoint_directory) if os.path.isdir(os.path.join(checkpoint_directory, folder))]\n","\n","# Create a select checkpoint dropdown UI\n","checkpoint_dropdown = widgets.Dropdown(\n","    options=list_of_checkpoints,\n","    description='Select a checkpoint to upload to hugging face:'\n",")\n","\n","# Creating repository_name_input UI\n","repository_name_input = widgets.Text(\n","    value='',  # Initial value of the input field\n","    placeholder='E.g TestModel (no whitespaces)',  # Placeholder text\n","    description='New repo name:',  # Label for the input field\n","    layout=widgets.Layout(width='30%')\n",")\n","\n","# Creating repository_name_input UI\n","repository_upload_destination_input = widgets.Text(\n","    value='',  # Initial value of the input field\n","    placeholder='E.g TestModel (no whitespaces)',  # Placeholder text\n","    description='Enter repo name:',  # Label for the input field\n","    layout=widgets.Layout(width='30%')\n",")\n","\n","# On 'Create new repository button' click, a new repo will be created in hugging face account\n","def on_button_click(b):\n","    # Will create a repo once only need to change to a new repository name on each run of this cell\n","    repository_name = repository_name_input.value\n","    repo_id = hf_api.create_repo(repository_name)\n","\n","# Define a function to upload model to hugging face\n","def upload_click(b):\n","  # Path to model directory\n","  model_directory = \"/content/ict3104-team13-2023/checkpoints/\"\n","\n","  # Concatenate chosen checkpoint\n","  model_directory += checkpoint_dropdown.value\n","  hf_api.upload_folder(\n","    folder_path= model_directory,\n","    repo_id=\"3104FYPHuggingFace/\" + repository_upload_destination_input.value,\n","    repo_type=\"model\",\n","  )\n","\n","# Define a function to handle the dropdown value change\n","def on_dropdown_change(change):\n","    selected_folder = change.new\n","\n","# Attach the option change to checkpoint_dropdown\n","checkpoint_dropdown.observe(on_dropdown_change, names='value')\n","\n","# Attach the event handler to the button\n","add_new_repository_button.on_click(on_button_click)\n","upload_to_repo_button.on_click(upload_click)\n","\n","# Display the button\n","display(repository_name_input)\n","display(add_new_repository_button)\n","display(HTML(html_code))\n","display(repository_upload_destination_input)\n","display(checkpoint_dropdown)\n","display(upload_to_repo_button)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title US T13-35 Download Models from Hugging Face\n","\n","# from transformers import HfApi, HfFolder, logging, set_seed\n","from huggingface_hub import HfApi, HfFolder, notebook_login, create_repo, snapshot_download\n","from ipywidgets import widgets, HBox, Layout\n","from IPython.display import display, HTML\n","import os\n","import subprocess\n","\n","html_code = \"<br/><br/><br/>\"  # Space HTML\n","\n","api_upload_token = \"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\"\n","\n","hf_api = HfApi(\n","    endpoint=\"https://huggingface.co\", # endpoint.\n","    token=api_upload_token, # Token is not persisted on the machine.\n",")\n","\n","checkpoint_directory = \"/content/ict3104-team13-2023/checkpoints\"\n","list_of_checkpoints = [folder for folder in os.listdir(checkpoint_directory) if os.path.isdir(os.path.join(checkpoint_directory, folder))]\n","\n","# Create a select checkpoint dropdown UI\n","checkpoint_dropdown = widgets.Dropdown(\n","    options=list_of_checkpoints,\n","    description='Select a checkpoint to upload to hugging face:'\n",")\n","\n","# Creating add_new_repository_button UI\n","download_from_repository_button = widgets.Button(\n","    description='Download from repository',  # Button label\n","    layout=Layout(width='150px')  # Adjust the width as needed\n",")\n","\n","# On 'download_from_repository_button' click, model in that repo will be downloaded\n","def on_button_click(b):\n","    # snapshot_download(repo_id=\"3104FYPHuggingFace/TestModel\")\n","    try:\n","        # Run the Git LFS clone command\n","        subprocess.run([\"git\", \"lfs\", \"clone\", \"https://huggingface.co/3104FYPHuggingFace/TestModel\", os.getcwd()], check=True)\n","        print(f\"Successfully cloned the model to {os.getcwd()}\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"Failed to clone the model: {e}\")\n","\n","# Define a function to handle the dropdown value change\n","def on_dropdown_change(change):\n","    print(checkpoint_directory)\n","    new_directory = checkpoint_directory + \"/\" + checkpoint_dropdown.value\n","    if os.path.isdir(new_directory):\n","        os.chdir(new_directory)\n","        # Now, the current working directory is changed to selected_folder\n","        print(f\"Changed directory to: {os.getcwd()}\")\n","    else:\n","        print(f\"The selected folder does not exist or is not a directory.\")\n","\n","\n","download_from_repository_button.on_click(on_button_click)\n","# Attach the option change to checkpoint_dropdown\n","checkpoint_dropdown.observe(on_dropdown_change, names='value')\n","\n","# Display the button\n","display(download_from_repository_button)\n","display(checkpoint_dropdown)"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º Data Exploration"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title US T13-31 Select Dataset for Training / Testing \n","\n","import os\n","import ipywidgets as widgets\n","from IPython.display import display\n","\n","data_folder = '/content/ict3104-team13-2023/data_folder'\n","\n","# Define functions to handle button clicks\n","def choose_training_folder(b):\n","    training_subfolder = training_dropdown.value\n","    print(f'Selected training subfolder: {training_subfolder}')\n","\n","def choose_testing_folder(b):\n","    testing_subfolder = testing_dropdown.value\n","    print(f'Selected testing subfolder: {testing_subfolder}')\n","\n","# List subfolders in the data folder\n","subfolders = [f for f in os.listdir(data_folder) if os.path.isdir(os.path.join(data_folder, f))]\n","\n","# Create dropdown widgets for training and testing\n","training_dropdown = widgets.Dropdown(\n","    options=subfolders,\n","    description='Folder:',\n",")\n","testing_dropdown = widgets.Dropdown(\n","    options=subfolders,\n","    description='Folder:',\n",")\n","\n","# Create buttons to trigger the folder selection\n","train_button = widgets.Button(description=\"Training\")\n","test_button = widgets.Button(description=\"Testing\")\n","\n","# Assign the functions to be called when the buttons are clicked\n","train_button.on_click(choose_training_folder)\n","test_button.on_click(choose_testing_folder)\n","\n","# Display the widgets\n","display(training_dropdown, train_button)\n","display(testing_dropdown, test_button)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@title US T13-3 Input files subfolders\n","\n","import os\n","\n","main_folder = '/content/ict3104-team13-2023/data_folder'\n","\n","if not os.path.exists(main_folder):\n","    os.mkdir(main_folder)\n","\n","subfolders = ['stickman', 'others']\n","\n","for subfolder in subfolders:\n","    subfolder_path = os.path.join(main_folder, subfolder)\n","\n","    if not os.path.exists(subfolder_path):\n","        os.mkdir(subfolder_path)\n","        print(f\"Created subfolder '{subfolder_path}'\")"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title US T13-17 Testing Subfolders\n","\n","import os\n","\n","main_folder = '/content/ict3104-team13-2023/data_folder/testing'\n","\n","if not os.path.exists(main_folder):\n","    os.mkdir(main_folder)\n","\n","subfolders = ['stickman']\n","\n","for subfolder in subfolders:\n","    subfolder_path = os.path.join(main_folder, subfolder)\n","\n","    if not os.path.exists(subfolder_path):\n","        os.mkdir(subfolder_path)\n","        print(f\"Created subfolder '{subfolder_path}'\")"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@title  US T13-4 Load Video (Edited by US T13-33)\n","\n","!apt-get install ffmpeg\n","\n","import ipywidgets as widgets\n","import os\n","from IPython.display import HTML, display, Image\n","from base64 import b64encode\n","\n","input_folder = '/content/ict3104-team13-2023/data_folder/stickman/'\n","output_folder = '/content/ict3104-team13-2023/data_folder/stickman/converted/'\n","\n","if not os.path.exists(output_folder):\n","    os.makedirs(output_folder)\n","\n","for filename in os.listdir(input_folder):\n","    if filename.endswith(\".mp4\"):\n","        input_file = os.path.join(input_folder, filename)\n","        output_file = os.path.join(output_folder, filename)\n","        cmd = f'ffmpeg -i \"{input_file}\" -vcodec libx264 \"{output_file}\"'\n","        os.system(cmd)\n","\n","skeleton_list = []\n","charades_list = []\n","prompt_list = []\n","\n","skeleton_directory = 'data_folder/stickman/converted'\n","charades_directory = 'charades'\n","prompt_directory = '/content/ict3104-team13-2023/data_folder/inference_result'\n","\n","current_directory = os.getcwd()\n","\n","# store video names in list\n","for file in os.listdir(os.path.join(current_directory, skeleton_directory)):\n","    if file[0] != \".\":\n","        skeleton_list.append(file)\n","for file in os.listdir(os.path.join(current_directory, charades_directory)):\n","    if file[0] != \".\":\n","        charades_list.append(file)\n","for file in os.listdir(prompt_directory):\n","    if file[0] != \".\":\n","        prompt_list.append(file)\n","\n","# Create labels for each dropdown\n","skeleton_label = widgets.Label(value=\"Skeleton:\")\n","charades_label = widgets.Label(value=\"Charades:\")\n","prompt_label = widgets.Label(value=\"Prompt:\")\n","gif_label = widgets.Label(value=\"GIF:\")\n","\n","# show vid name in list as dropdown\n","skeleton_dropdown = widgets.Dropdown(options=skeleton_list, value=None)\n","charades_dropdown = widgets.Dropdown(options=charades_list, value=None)\n","prompt_dropdown = widgets.Dropdown(options=prompt_list, value=None)\n","gif_dropdown = widgets.Dropdown(options=[\"Please select a gif\"], value=None)\n","\n","# Group each label and dropdown together using an HBox\n","skeleton_box = widgets.HBox([skeleton_label, skeleton_dropdown])\n","charades_box = widgets.HBox([charades_label, charades_dropdown])\n","prompt_box = widgets.HBox([prompt_label, prompt_dropdown])\n","gif_box = widgets.HBox([gif_label, gif_dropdown])\n","\n","skeleton_output = widgets.Output()\n","charades_output = widgets.Output()\n","prompt_output = widgets.Output()\n","gif_output = widgets.Output()\n","display(skeleton_box, charades_box, prompt_box, gif_box, skeleton_output, charades_output, prompt_output, gif_output)\n","\n","# UI functions\n","def on_dropdown_change(change):\n","    dropdown = change['owner']\n","    if dropdown is skeleton_dropdown:\n","        display_media(\"skeleton\", skeleton_directory, change['new'])\n","    elif dropdown is charades_dropdown:\n","        display_media(\"charades\", charades_directory, change['new'])\n","    elif dropdown is prompt_dropdown:\n","        prompt_output.clear_output()  # Clear the previous output\n","        gif_output.clear_output()  # Clear the previous gif_output\n","        display(prompt_output)\n","\n","        selected_prompt = change.new\n","        prompt_gifs = [file for file in os.listdir(os.path.join(prompt_directory, selected_prompt)) if not file.startswith('.')]\n","        gif_dropdown.options = [\"Please select a gif\"] + prompt_gifs  # Update the gif_dropdown options\n","\n","def on_gif_dropdown_change(change):\n","    selected_gif = change.new\n","    if selected_gif != \"Please select a gif\":\n","        display_media(\"output\", os.path.join(prompt_directory, prompt_dropdown.value), selected_gif)\n","\n","# Observe changes in the dropdowns\n","skeleton_dropdown.observe(on_dropdown_change, names='value')\n","charades_dropdown.observe(on_dropdown_change, names='value')\n","prompt_dropdown.observe(on_dropdown_change, names='value')\n","gif_dropdown.observe(on_gif_dropdown_change, names='value')\n","\n","# UI functions\n","def display_media(typeToShow, directory, value):\n","    video_path = os.path.join(current_directory, directory + '/' + value)\n","    if typeToShow == \"skeleton\":\n","        with skeleton_output:\n","            skeleton_mp4 = open(video_path, 'rb').read()\n","            skeleton_data_url = \"data:video/mp4;base64,\" + b64encode(skeleton_mp4).decode()\n","            if skeleton_mp4 and skeleton_data_url:\n","                video_html = f'<h1>Skeleton:</h1><video width=\"200\" height=\"200\" controls><source src=\"{skeleton_data_url}\" type=\"video/mp4\"></video>'\n","                display(HTML(video_html))\n","            else:\n","                print(\"Cannot open chosen skeleton video\")\n","    elif typeToShow == \"charades\":\n","        with charades_output:\n","            charades_mp4 = open(video_path, 'rb').read()\n","            charades_data_url = \"data:video/mp4;base64,\" + b64encode(charades_mp4).decode()\n","            if charades_mp4 and charades_data_url:\n","                video_html = f'<h1>Charades:</h1><video width=\"200\" height=\"200\" controls><source src=\"{charades_data_url}\" type=\"video/mp4\"></video>'\n","                display(HTML(video_html))\n","            else:\n","                print(\"Cannot open chosen charades video\")\n","    elif typeToShow == \"output\":\n","        with gif_output:\n","            clear_output()\n","            display(HTML(\"Generated Gif:\"))\n","            display(Image(filename=video_path))\n","            display(HTML(f\"<div style='text-align: center;'><p> {prompt_dropdown.value}</p></div>\"))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Kbx46ZU6znrs"},"source":["# ðŸ•ºðŸ•ºðŸ•º Inference"]},{"cell_type":"markdown","metadata":{"id":"6GW8-Xz8zwnE"},"source":["Due to memory of GPU, we recommend set video_length=8 in ./config/pose_sample.yaml for running successfully. \n","\n","Meanwhile, we should keep the skeleton frame length(./followyourpose/pipelines/pipeline_followyourpose.py:422 ) equal with video_length"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["%cd /content/FollowYourPose\n","!pwd\n","!TORCH_DISTRIBUTED_DEBUG=DETAIL accelerate launch txt2video.py --config=\"configs/pose_sample.yaml\"  --skeleton_path=\"./pose_example/vis_ikun_pose2.mov\""]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# @title US T13-16 Select skeleton video and perform inference (integrated with US T13-6 and T13-28)\n","import os\n","from ipywidgets import interact, widgets\n","from IPython.display import display, HTML, Image, clear_output\n","from functools import partial\n","import subprocess\n","import yaml\n","\n","\n","# Declare file_dropdown as a global variable\n","file_dropdown = None\n","stickman_directory = '/content/ict3104-team13-2023/data_folder/stickman'\n","input_path = \"\"\n","\n","\n","\n","\n","def display_file_dropdown():\n","    # Define the directory path\n","\n","    # Get a list of files in the directory\n","    files = os.listdir(stickman_directory)\n","\n","    # Create a dropdown widget with the default value set to None\n","    global file_dropdown\n","    file_dropdown = widgets.Dropdown(\n","        options=[''] + files,\n","        description='Select File:',\n","        disabled=False,\n","        value=None,\n","    )\n","\n","\n","\n","    # Create an output widget to display the selected file\n","    output = widgets.Output()\n","\n","    # Define a function to handle the dropdown selection\n","    def on_file_select(change):\n","        selected_file = change.new\n","        with output:\n","            clear_output()\n","            # Display the selected MP4 file\n","            if selected_file:\n","                print(f\"Selected File: {selected_file}\")\n","            else:\n","                print(\"No file selected\")\n","\n","    # Attach the function to the dropdown's change event\n","    file_dropdown.observe(on_file_select, names='value')\n","\n","    # Display the dropdown and the output widget\n","    display(file_dropdown)\n","    display(output)\n","\n","# method to add user's prompt into pose_sample.yaml\n","def insert_prompt_input_into_config(prompt):\n","\n","  # Load the YAML file\n","  with open('/content/ict3104-team13-2023/configs/pose_sample.yaml', 'r') as file:\n","      config = yaml.safe_load(file)\n","\n","  # Access the 'prompts' section\n","  config['validation_data']['prompts'] = [prompt]\n","\n","  # Save the modified configuration back to the file\n","  with open('/content/ict3104-team13-2023/configs/pose_sample.yaml', 'w') as file:\n","      yaml.dump(config, file, default_flow_style=False)\n","\n","\n","def on_button_click(b):\n","    # Perform an action when the button is clicked\n","    insert_prompt_input_into_config(prompt_input.value)\n","    selected_file = file_dropdown.value\n","    if selected_file:\n","        global input_path\n","        input_path = os.path.join(stickman_directory, selected_file)\n","\n","        !TORCH_DISTRIBUTED_DEBUG=DETAIL accelerate launch txt2video.py --config=\"configs/pose_sample.yaml\"  --skeleton_path=\"{input_path}\"\n","\n","def user_input():\n","    # Call the function to display the dropdown\n","    display_file_dropdown()\n","\n","    global prompt_input\n","    # Show input to accept user prompt\n","    prompt_input = widgets.Text(\n","      value='',  # Initial value\n","      placeholder='Enter prompt...',  # Placeholder text\n","      description='Prompt Input: ',  # Label for the input\n","    )\n","\n","    # Create a button widget\n","    button = widgets.Button(description=\"Confirm\")\n","    button.on_click(on_button_click)\n","\n","    # Display the button\n","    display(prompt_input, button)\n","\n","# Call the user_input function\n","user_input()"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["# @title US T13-7 Function to combine gif\n","\n","import os\n","from moviepy.editor import VideoFileClip, clips_array\n","\n","# Function to combine a GIF with a matching skeleton video in the same directory\n","def combine_and_create_gif(prompt, gif_path, skeleton_folder, output_folder):\n","    # Get the base name of the GIF file (including the extension)\n","    file_name_with_extension = os.path.basename(gif_path)\n","\n","    # Split the file name from the extension\n","    file_name, file_extension = os.path.splitext(file_name_with_extension)\n","\n","    # Search for a matching skeleton video in the skeleton folder\n","    skeleton_video_path = os.path.join(skeleton_folder, f\"{file_name}.mp4\")\n","\n","    if os.path.isfile(skeleton_video_path):\n","        print(f\"Processing GIF: {file_name} in prompt: {prompt}\")\n","\n","        # Loading the GIF and skeleton videos\n","        gif_video = VideoFileClip(gif_path)\n","        skeleton_video = VideoFileClip(skeleton_video_path)\n","\n","        # Determine the minimum duration of the two videos\n","        common_duration = min(gif_video.duration, skeleton_video.duration)\n","\n","        # Trim both videos to the common duration\n","        gif_video = gif_video.subclip(0, common_duration)\n","        skeleton_video = skeleton_video.subclip(0, common_duration)\n","\n","        # Directory for the output GIF\n","        output_directory = os.path.join(output_folder, prompt)\n","        output_gif_path = os.path.join(output_directory, file_name + file_extension)\n","\n","        print(f\"Output Directory: {output_directory}\")\n","        print(f\"Output GIF Path: {output_gif_path}\")\n","\n","        # Ensure the output directory exists, or create it if it doesn't\n","        os.makedirs(output_directory, exist_ok=True)\n","\n","        # Resize both videos to have the same width and height\n","        min_width = 512\n","        min_height = 512\n","        gif_video = gif_video.resize((min_width, min_height))\n","        skeleton_video = skeleton_video.resize((min_width, min_height))\n","\n","        # Combine the videos side by side\n","        result = clips_array([[skeleton_video, gif_video]])\n","\n","        # Write as GIF for display\n","        result.write_gif(output_gif_path, fps=30)\n","        print(f\"Output GIF created successfully.\")\n","\n","    else:\n","        print(f\"No matching skeleton video found for {file_name}.\")\n","\n","# Directory containing the input GIFs\n","input_directory = \"/content/ict3104-team13-2023/data_folder/inference\"\n","\n","# Directory containing skeleton videos\n","skeleton_directory = \"/content/ict3104-team13-2023/data_folder/stickman\"\n","\n","# Directory for the output GIFs\n","output_directory = \"/content/ict3104-team13-2023/data_folder/inference_result\"\n","\n","# Function to process all GIFs in the input directory\n","def process_all_gifs(input_directory, skeleton_directory, output_directory):\n","    # Get a list of all subdirectories (prompts) in the input directory\n","    prompts = [prompt for prompt in os.listdir(input_directory) if os.path.isdir(os.path.join(input_directory, prompt))]\n","\n","    for prompt in prompts:\n","        prompt_folder = os.path.join(input_directory, prompt)\n","        gif_files = [f for f in os.listdir(prompt_folder) if f.endswith(\".gif\")]\n","\n","        for gif_file in gif_files:\n","            gif_path = os.path.join(prompt_folder, gif_file)\n","            combine_and_create_gif(prompt, gif_path, skeleton_directory, output_directory)\n","\n","# Process all GIFs in the input directory\n","process_all_gifs(input_directory, skeleton_directory, output_directory)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title Display inferenced videos with captions\n","import os\n","import ipywidgets as widgets\n","from IPython.display import display, HTML, Image, clear_output\n","\n","# Root directory for inference GIFs\n","root_directory = \"/content/ict3104-team13-2023/data_folder/inference_result\"\n","\n","# Get a list of prompts (subdirectories)\n","prompts = [prompt for prompt in os.listdir(root_directory) if os.path.isdir(os.path.join(root_directory, prompt))]\n","\n","# Create dropdowns\n","prompt_dropdown = widgets.Dropdown(options=prompts, description='Select Prompt:')\n","gif_dropdown = widgets.Dropdown(description='Select GIF:')\n","submit_button = widgets.Button(description='Display GIF')\n","output_image = widgets.Output()\n","\n","# Store the initial values of the dropdowns\n","initial_prompt_value = None\n","initial_gif_value = None\n","\n","# Function to update the GIF dropdown based on the selected prompt\n","def update_gif_dropdown(change):\n","    selected_prompt = change.new\n","    prompt_folder = os.path.join(root_directory, selected_prompt)\n","    gif_files = [f for f in os.listdir(prompt_folder) if f.endswith(\".gif\")]\n","    gif_dropdown.options = gif_files\n","\n","# Function to display the selected GIF with centered prompt as caption\n","def display_gif(prompt, gif):\n","    global initial_prompt_value, initial_gif_value\n","\n","    prompt_folder = os.path.join(root_directory, prompt)\n","    gif_path = os.path.join(prompt_folder, gif)\n","\n","    # Store the current values\n","    initial_prompt_value = prompt\n","    initial_gif_value = gif\n","\n","    # Clear previous output\n","    with output_image:\n","        clear_output(wait=True)\n","\n","        # Display the selected GIF with centered prompt as caption\n","        display(Image(filename=gif_path))\n","        display(HTML(f\"<div style='text-align: center;'><p> {prompt}</p></div>\"))\n","\n","# Function to handle dropdown selection and submit\n","def on_submit_button_clicked(b):\n","    display_gif(prompt_dropdown.value, gif_dropdown.value)\n","\n","# Link the update function to the value of the prompt dropdown\n","prompt_dropdown.observe(update_gif_dropdown, names='value')\n","\n","# Attach the button click event handler\n","submit_button.on_click(on_submit_button_clicked)\n","\n","# Display the dropdown and the submit button\n","widgets.VBox([prompt_dropdown, gif_dropdown, submit_button, output_image])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title  US T13-32\n","\n","import cv2\n","import numpy as np\n","\n","# Function to remove black background from skeleton video with adjustable transparency\n","def remove_black_background(skeleton_video_path, output_video_path, alpha):\n","    # Open the skeleton video\n","    skeleton_video = cv2.VideoCapture(skeleton_video_path)\n","\n","    # Get the dimensions of the input video\n","    width = int(skeleton_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    height = int(skeleton_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","    # Open the output video writer\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","    output_video = cv2.VideoWriter(output_video_path, fourcc, 30, (width, height))\n","\n","    while skeleton_video.isOpened():\n","        ret, frame = skeleton_video.read()\n","        if not ret:\n","            break\n","\n","        # Overlay the skeleton frame on the output frame with adjustable transparency\n","        frame = cv2.addWeighted(frame, alpha, frame, 1 - alpha, 0)\n","\n","        # Write the frame to the output video\n","        output_video.write(frame)\n","\n","    # Release video objects\n","    skeleton_video.release()\n","    output_video.release()\n","\n","# Input and output directories\n","input_directory = '/content/ict3104-team13-2023/data_folder/stickman'\n","output_directory = '/content/ict3104-team13-2023/data_folder/stickman_without_background'\n","\n","# Create the output directory if it doesn't exist\n","os.makedirs(output_directory, exist_ok=True)\n","\n","# List all .mp4 video files in the input directory\n","video_files = [f for f in os.listdir(input_directory) if f.endswith('.mp4')]\n","\n","for video_file in video_files:\n","    # Construct full paths for input and output videos\n","    input_video_path = os.path.join(input_directory, video_file)\n","    output_video_path = os.path.join(output_directory, video_file)\n","\n","    # Call the function to remove the black background with adjustable transparency\n","    remove_black_background(input_video_path, output_video_path, alpha=1)  # Adjust alpha as needed\n","\n","print(\"Background removal completed for all videos with transparency.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["import os\n","import cv2\n","import imageio\n","\n","# Function to combine videos and save as GIFs\n","def combine_videos_as_gifs(inference_directory, stickman_without_background_dir, output_directory):\n","    # Loop through each prompt directory in the inference folder\n","    for prompt_name in os.listdir(inference_directory):\n","        prompt_directory = os.path.join(inference_directory, prompt_name)\n","\n","        # Check if it's a directory\n","        if not os.path.isdir(prompt_directory):\n","            continue\n","\n","        # Create the output directory for the prompt if it doesn't exist\n","        prompt_output_directory = os.path.join(output_directory, prompt_name)\n","        os.makedirs(prompt_output_directory, exist_ok=True)\n","\n","        # Loop through each output file in the prompt directory\n","        for output_file in os.listdir(prompt_directory):\n","            # Check if the file is a GIF\n","            if not output_file.endswith('.gif'):\n","                continue\n","\n","            # Load the output GIF\n","            output_gif_path = os.path.join(prompt_directory, output_file)\n","            output_gif = cv2.VideoCapture(output_gif_path)\n","\n","            # Find the corresponding skeleton video in the stickman_without_background directory\n","            skeleton_video_path = os.path.join(stickman_without_background_dir, output_file.replace('.gif', '.mp4'))\n","\n","            # Check if the skeleton video file exists\n","            if not os.path.exists(skeleton_video_path):\n","                print(f\"Skeleton video not found for {output_file}. Skipping.\")\n","                continue\n","\n","            # Get the frame dimensions from the first frame\n","            ret_output, frame_output = output_gif.read()\n","\n","            if not ret_output:\n","                print(f\"Error reading the first frame of {output_file}. Skipping.\")\n","                continue\n","\n","            # Initialize the combined frames list\n","            combined_frames = []\n","\n","            # Load the skeleton video\n","            skeleton_video = cv2.VideoCapture(skeleton_video_path)\n","\n","            while skeleton_video.isOpened() and output_gif.isOpened():\n","                ret_skeleton, frame_skeleton = skeleton_video.read()\n","                ret_output, frame_output = output_gif.read()\n","\n","                if not ret_skeleton or not ret_output:\n","                    break\n","\n","                # Overlay the skeleton frame on the output frame\n","                frame_skeleton = cv2.resize(frame_skeleton, (frame_output.shape[1], frame_output.shape[0]))\n","\n","                # Convert both frames to the same data type before adding\n","                frame_skeleton = frame_skeleton.astype(frame_output.dtype)\n","\n","                # Adjust the alpha value to make the skeleton more or less visible\n","                alpha = 1.8 # You can experiment with different values (e.g., 0.7, 0.8, 0.9)\n","\n","                # Use cv2.add() with the same data type for input and output\n","                combined_frame = cv2.add(frame_output, alpha * frame_skeleton, dtype=cv2.CV_8U)\n","                combined_frames.append(cv2.cvtColor(combined_frame, cv2.COLOR_BGR2RGB))\n","\n","            # Save the combined frames as a GIF with looping\n","            combined_gif_path = os.path.join(prompt_output_directory, output_file)\n","            imageio.mimsave(combined_gif_path, combined_frames, duration=1/10, loop=0)  # Set loop parameter to 0 for infinite looping\n","\n","            # Release video capture objects\n","            output_gif.release()\n","            skeleton_video.release()\n","\n","            print(f\"Combined GIF for {output_file} in prompt {prompt_name} created successfully.\")\n","\n","# Define the input and output directories\n","inference_directory = \"/content/ict3104-team13-2023/data_folder/inference\"\n","stickman_without_background_dir = \"/content/ict3104-team13-2023/data_folder/stickman_without_background\"\n","output_directory = \"/content/ict3104-team13-2023/data_folder/inference_skeleton_overlay\"\n","\n","# Combine all videos as GIFs with looping\n","combine_videos_as_gifs(inference_directory, stickman_without_background_dir, output_directory)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["import os\n","import ipywidgets as widgets\n","from IPython.display import display, HTML, Image, clear_output\n","from ipywidgets import Output\n","\n","# Get the list of prompt directories in the inference_skeleton_overlay directory\n","prompt_dir = '/content/ict3104-team13-2023/data_folder/inference_skeleton_overlay'\n","prompt_dirs = [d for d in os.listdir(prompt_dir) if os.path.isdir(os.path.join(prompt_dir, d))]\n","\n","# Create an Output widget to display the GIF\n","output_area = Output()\n","\n","# Create a dropdown widget for selecting the prompt\n","prompt_dropdown = widgets.Dropdown(\n","    options=prompt_dirs,\n","    description='Select Prompt:',\n",")\n","\n","# Create a second dropdown for selecting the GIF within the selected prompt\n","gif_dropdown = widgets.Dropdown(\n","    description='Select GIF:',\n",")\n","\n","# Create a button for displaying the selected GIF\n","display_button = widgets.Button(description=\"Display GIF\")\n","\n","# Function to update the GIF dropdown based on the selected prompt\n","def update_gif_dropdown(change):\n","    selected_prompt = change['new']\n","    gif_files = [f for f in os.listdir(os.path.join(prompt_dir, selected_prompt)) if f.endswith('.gif')]\n","    gif_dropdown.options = gif_files\n","\n","# Attach the update function to the prompt dropdown\n","prompt_dropdown.observe(update_gif_dropdown, names='value')\n","\n","# Function to display the selected GIF\n","def display_button_clicked(b):\n","    with output_area:\n","        output_area.clear_output()\n","        selected_prompt = prompt_dropdown.value\n","        selected_gif = gif_dropdown.value\n","        display_selected_gif(selected_prompt, selected_gif)\n","\n","# Attach the button click handler\n","display_button.on_click(display_button_clicked)\n","\n","# Function to display the selected GIF\n","def display_selected_gif(selected_prompt, selected_gif):\n","    # Check if the GIF file exists in the specified prompt directory\n","    gif_path = os.path.join(prompt_dir, selected_prompt, selected_gif)\n","    if os.path.isfile(gif_path):\n","        # Display the GIF\n","        display(Image(filename=gif_path))\n","    else:\n","        print(\"GIF file not found in the specified directory.\")\n","\n","# Display the prompt dropdown, GIF dropdown, and display button\n","display(widgets.VBox([prompt_dropdown, gif_dropdown, display_button, output_area]))\n"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º Training"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@title  User Story T13-8: Select subfolder from dataset folder\n","import ipywidgets as widgets\n","import os, cv2\n","from os import listdir\n","from ipywidgets import Dropdown, interact\n","\n","data_directory = \"./dataset_folder\"\n","directory_dict = {}\n","\n","# get subfolders as key and list of files as value in dict\n","for root, subfolders, files in os.walk(data_directory):\n","    # Skip the root directory itself\n","    if root == data_directory:\n","        continue\n","\n","    subfolder_name = os.path.relpath(root, data_directory)\n","\n","    if \".ipynb\" in subfolder_name:\n","      continue\n","    # Create a list of file names in the subfolder\n","    file_names = [file for file in files]\n","    # Add the subfolder and its file names to the dictionary\n","    directory_dict[subfolder_name] = file_names\n","#print(directory_dict)\n","\n","\n","# dropdown UI\n","subfolder_choices = Dropdown(options =directory_dict.keys())\n","subfolder_files = Dropdown()\n","button = widgets.Button(description=\"Select dataset\")\n","\n","\n","@interact(subfolder = subfolder_choices, dataset = subfolder_files)\n","def print_city(subfolder, dataset):\n","    subfolder_files.options = directory_dict[subfolder]\n","\n","# UI\n","display(button)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@title  User Story T13-6\n","import ipywidgets as widgets\n","import os, cv2\n","import subprocess\n","import yaml\n","from os import listdir\n","from google.colab.patches import cv2_imshow\n","from IPython.display import HTML, clear_output\n","from base64 import b64encode\n","\n","\n","# Define and Instantiate variables\n","charades_data_url = None\n","charades_video_path = \"./charades\"\n","charades_video_list = []\n","chosen_charades_video = None\n","\n","# Store names of charades video in a list\n","for file in os.listdir(charades_video_path):\n","  charades_video_list.append(file)\n","\n","# Show input to accept user prompt\n","prompt_input = widgets.Text(\n","    value='',  # Initial value\n","    placeholder='Enter prompt...',  # Placeholder text\n","    description='Prompt Input: ',  # Label for the input\n",")\n","\n","# Add names of charades video as dropdown options\n","charades_videos_dropdown = widgets.Dropdown(options=charades_video_list, value=None)\n","\n","# UI to show after running this cell\n","choose_charades_video_button = widgets.Button(description=\"Choose Video\")\n","chosen_video_output = widgets.Output()\n","\n","# Display all UI\n","display(prompt_input, charades_videos_dropdown, choose_charades_video_button, chosen_video_output)\n","\n","# method to add user's prompt into pose_sample.yaml\n","def insert_prompt_input_into_config(prompt):\n","\n","  # Load the YAML file\n","  with open('./configs/pose_sample.yaml', 'r') as file:\n","      config = yaml.safe_load(file)\n","\n","  # Access the 'prompts' section\n","  config['validation_data']['prompts'] = [prompt]\n","\n","\n","  # Save the modified configuration back to the file\n","  with open('./configs/pose_sample.yaml', 'w') as file:\n","      yaml.dump(config, file, default_flow_style=False)\n","\n","def generate_gif():\n","  # Change directory to /content/ict3104-team13-2023\n","  os.chdir('/content/ict3104-team13-2023')\n","\n","  # Print the current working directory\n","  print(os.getcwd())\n","\n","  # Set the TORCH_DISTRIBUTED_DEBUG environment variable and launch txt2video.py\n","  subprocess.run(['accelerate', 'launch', 'txt2video.py', '--config=configs/pose_sample.yaml', '--skeleton_path=./pose_example/vis_ikun_pose2.mov'])\n","\n","#\n","def set_charades_video_variables(charades_video_name):\n","  if charades_video_name is not None:\n","    # print(\"Have something\")\n","    pass\n","  with chosen_video_output:\n","        charades_mp4 = open(charades_video_path +'/'+ charades_video_name,'rb').read()\n","        charades_data_url = \"data:video/mp4;base64,\" + b64encode(charades_mp4).decode()\n","        if charades_mp4 and charades_data_url:\n","          video_html = f'<video controls><source src=\"{charades_data_url}\" type=\"video/mp4\"></video>'\n","          # Clear previous output\n","          clear_output()\n","          display(HTML(video_html))\n","        else:\n","          print(\"Cannot open chosen charades video\")\n","\n","# OnClick function for 'Choose Video' button\n","def on_choose_charades_video_button_clicked(b):\n","    pass\n","\n","# OnChange function for dropdown\n","def on_charades_videos_dropdown_change(change):\n","    if change['name'] == 'value' and change['new']:\n","        chosen_charades_video = change['new']\n","        selected_option = change['new']\n","        # print(f\"Selected option: {selected_option}\")\n","        set_charades_video_variables(selected_option)\n","\n","# On Prompt Input 'enter' key press\n","def on_prompt_input_enter_pressed(change):\n","      # print(\"Enter pressed with text:\", prompt_input.value)\n","      insert_prompt_input_into_config(prompt_input.value)\n","      generate_gif()\n","\n","# Attach event functions to UI\n","prompt_input.on_submit(on_prompt_input_enter_pressed)\n","charades_videos_dropdown.observe(on_charades_videos_dropdown_change, names='value')\n","choose_charades_video_button.on_click(on_choose_charades_video_button_clicked)"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#Implement progress bar here "]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º MMPose"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title Environment Setup\n","!update-alternatives --install /usr/local/bin/python3 python3 /usr/bin/python3.8 2\n","!update-alternatives --install /usr/local/bin/python3 python3 /usr/bin/python3.9 1\n","!python --version\n","!apt-get update\n","!apt install software-properties-common\n","!sudo dpkg --remove --force-remove-reinstreq python3-pip python3-setuptools python3-wheel\n","!apt-get install python3-pip\n","\n","%cd /content\n","\n","# forked michael's mmpose because project needed to change some of the mmpose code\n","!git clone https://github.com/micdiary/mmpose.git\n","\n","#MMPose\n","%cd /content/mmpose\n","!python3 -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","# install MMEngine, MMCV and MMDetection using MIM\n","!python3 -m pip install -U openmim\n","!mim install mmengine\n","!mim install \"mmcv>=2.0.0\"\n","!mim install \"mmdet>=3.0.0\"\n","\n","!python3 -m pip install -r requirements.txt\n","!python3 -m pip install -v -e .\n","\n","!python3 -m pip install setuptools==68.1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title Check MMpose\n","\n","%cd /content/mmpose/\n","\n","# Check Pytorch installation\n","import torch, torchvision\n","\n","print('torch version:', torch.__version__, torch.cuda.is_available())\n","print('torchvision version:', torchvision.__version__)\n","\n","# Check MMPose installation\n","import mmpose\n","\n","print('mmpose version:', mmpose.__version__)\n","\n","# Check mmcv installation\n","from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n","\n","print('cuda version:', get_compiling_cuda_version())\n","print('compiler information:', get_compiler_version())"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title Inference with MMPOSE\n","# run inference on ALL videos in the charades folder\n","import os\n","\n","%cd /content/mmpose\n","\n","charades_video_path = \"/content/ict3104-team13-2023/charades/\"\n","\n","# List all the MP4 files in the specified directory\n","mp4_files = [f for f in os.listdir(charades_video_path) if f.endswith('.mp4')]\n","\n","\n","# Iterate through the MP4 files and run the script for each one\n","for mp4_file in mp4_files:\n","    input_path = os.path.join(charades_video_path, mp4_file)\n","    output_folder = f\"/content/ict3104-team13-2023/data_folder/stickman/\"\n","\n","    !python demo/topdown_demo_with_mmdet.py \\\n","    demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py \\\n","    https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n","    configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-256x192.py \\\n","    https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth \\\n","    --input {input_path} \\\n","    --output-root {output_folder}"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title Inference with MMPOSE (1 video)\n","# run inference on 1 video\n","import os\n","\n","%cd /content/mmpose\n","\n","charades_video_path = \"/content/ict3104-team13-2023/charades/52CKM.mp4\"\n","\n","output_folder = f\"/content/ict3104-team13-2023/data_folder/stickman3/\"\n","\n","!python demo/topdown_demo_with_mmdet.py \\\n","demo/mmdetection_cfg/faster_rcnn_r50_fpn_1class.py \\\n","https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n","configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-256x192.py \\\n","https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth \\\n","--input {charades_video_path} \\\n","--output-root {output_folder}"]},{"cell_type":"markdown","metadata":{},"source":["After conducting spam testing, we discovered that the first library we tested was superior to the other three libraries due to their outdated versions. Therefore, we will revert to using the first library, as it provides the desired skeleton result."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title  US T13-30\n","\n","import os\n","import tempfile\n","from base64 import b64encode\n","import ipywidgets as widgets\n","from moviepy.editor import VideoFileClip\n","from IPython.display import HTML, display, clear_output\n","\n","stickman_directory = '/content/ict3104-team13-2023/data_folder/stickman'\n","\n","output_directory = tempfile.mkdtemp()\n","converted_videos = []\n","\n","for video_file in os.listdir(stickman_directory):\n","    if video_file.endswith('.mp4'):\n","        video_path = os.path.join(stickman_directory, video_file)\n","        output_path = os.path.join(output_directory, os.path.splitext(video_file)[0] + '_h264.mp4')\n","\n","        clip = VideoFileClip(video_path)\n","        clip.write_videofile(output_path, codec='libx264', logger=None)\n","\n","        converted_videos.append(output_path)\n","        print(f\"Done converting {video_file}\")\n","\n","stickman_files = [f for f in os.listdir(output_directory) if f.endswith('_h264.mp4')]\n","\n","stickman_dropdown = widgets.Dropdown(\n","    options=stickman_files,\n","    description='Select Video:'\n",")\n","\n","output = widgets.Output()\n","\n","def display_selected_video(change):\n","    with output:\n","      clear_output()\n","      selected_video = change.new\n","      video_path = os.path.join(output_directory, selected_video)\n","\n","      with open(video_path, 'rb') as f:\n","          data = f.read()\n","          data_url = \"data:video/mp4;base64,\" + b64encode(data).decode()\n","          display(HTML(f\"\"\"\n","              <video controls autoplay>\n","                  <source src=\"{data_url}\" type=\"video/mp4\">\n","              </video>\n","          \"\"\"))\n","\n","stickman_dropdown.observe(display_selected_video, names='value')\n","display(stickman_dropdown)\n","display(output)"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º FID Scores"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#setup fid\n","!pip install pytorch-fid\n","!pip install ffmpeg\n","!pip install scipy==1.11.1"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","import os, sys, subprocess, re, shutil\n","from PIL import Image\n","from pathlib import Path\n","\n","fid_score_list = []\n","file_name_list = []\n","# Function to split video into frames\n","def split_video_into_frames(video_path, output_dir, restrict_frames):\n","    if restrict_frames:\n","      os.system(f\"ffmpeg -i {video_path} -vf 'select=lt(n\\\\,{restrict_frames})' {output_dir}%04d.png\")\n","    else:\n","      os.system(f\"ffmpeg -i {video_path} {output_dir}%04d.png\")\n","\n","# here for now but can remove if t13-32 is compiled\n","input_directory = \"/content/ict3104-team13-2023/data_folder/inference\"\n","stickman_without_background_dir = \"/content/ict3104-team13-2023/data_folder/stickman_without_background\"\n","##########################################################################################################\n","animation_gifs = os.listdir(input_directory)\n","stickman_mp4s = os.listdir(stickman_without_background_dir)\n","\n","# Output directories for frames\n","skeleton_frames_dir = \"/content/ict3104-team13-2023/data_folder/fid_skeleton_frames/\"\n","original_frames_dir = \"/content/ict3104-team13-2023/data_folder/fid_gif_frames/\"\n","\n","for animation, stickman in tqdm(zip(animation_gifs, stickman_mp4s),\n","                   total=len(os.listdir(input_directory)),\n","                   desc = \"Loading bar graph\"):\n","#for animation, stickman  in zip(animation_gifs, stickman_mp4s):\n","    # get file name\n","    name, filetype = animation.split(\".\")\n","    file_name_list.append(name)\n","    # The directory exists and is not empty, remove its contents\n","    shutil.rmtree(skeleton_frames_dir)\n","    shutil.rmtree(original_frames_dir)\n","\n","    os.makedirs(skeleton_frames_dir)\n","    os.makedirs(original_frames_dir)\n","\n","    split_video_into_frames(os.path.join(input_directory, animation), original_frames_dir, None)\n","    og_frame_path =  Path(original_frames_dir)\n","    files = [file for file in og_frame_path.iterdir() if file.is_file()]\n","    file_count = len(files)\n","    split_video_into_frames(os.path.join(stickman_without_background_dir, stickman), skeleton_frames_dir, file_count)\n","\n","    cmd = \"python -m pytorch_fid \"+skeleton_frames_dir+\" \"+original_frames_dir\n","    # Run the command and capture output\n","    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","    stdout, stderr = process.communicate()\n","\n","    # Print the standard output\n","    output_text = stdout.decode()\n","    fid_match = re.search(r'FID:\\s+([\\d.]+)', output_text)\n","    if fid_match:\n","        fid_score = float(fid_match.group(1))\n","        fid_score_list.append(fid_score)\n","    else:\n","        print(\"FID score not found in the output\")\n","\n","\n","plt.bar(file_name_list, fid_score_list, label=\"FID Scores\", color='b')\n","plt.xlabel(\"File names\")\n","plt.ylabel(\"FID Scores\")\n","plt.title(\"FID scores of files in directory\")\n","plt.legend()\n","plt.xticks(rotation=45)\n","plt.show()\n","\n","\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOyNNhRT8BBHJeqGAp6TaSp","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
