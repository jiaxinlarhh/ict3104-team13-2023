{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZI-7IKtJYIIf"},"source":["\n","# ðŸ•ºðŸ•ºðŸ•º Follow Your Pose ðŸ’ƒðŸ’ƒðŸ’ƒ: \n","# Pose-Guided Text-to-Video Generation using Pose-Free Videos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1680855034941,"user":{"displayName":"yue ma","userId":"10565880864345925493"},"user_tz":-480},"id":"GPBJ9ZPNWofP","outputId":"08c669fd-6983-48ab-805f-31878714772c"},"outputs":[],"source":["#@markdown Check type of GPU and VRAM available.\n","!nvidia-smi - -query-gpu = name, memory.total, memory.free - -format = csv, noheader\n","#make sure you are using Tesla T4, 15360 MiB, 15101 MiB\n"]},{"cell_type":"markdown","metadata":{"id":"JGTUagmtwwxo"},"source":["# ðŸ•ºðŸ•ºðŸ•º Install Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21760,"status":"ok","timestamp":1680855062851,"user":{"displayName":"yue ma","userId":"10565880864345925493"},"user_tz":-480},"id":"JmWCIBSnZP4l","outputId":"7cbd0308-8e11-4140-8bff-58d9368d4a13"},"outputs":[],"source":["# @title  Environment Setup\n","!apt-get update\n","!apt install software-properties-common\n","!sudo dpkg --remove --force-remove-reinstreq python3-pip python3-setuptools python3-wheel\n","!apt-get install python3-pip\n","\n","!git clone https: // github.com/jiaxinlarhh/ict3104-team13-2023.git\n","\n","!git clone https: // github.com/open-mmlab/mmpose.git\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# @title  Setup FollowYourPose & MMPose\n","\n","# FollowYourPose\n","!cd / content/ict3104-team13-2023\n","!export PYTHONPATH = /content/ict3104-team13-2023: $PYTHONPATH\n","!python - m pip install - q - U - -pre triton\n","!apt update\n","!python - m pip install - q diffusers == 0.11.1 torch == 1.13.1 transformers == 4.26.0 bitsandbytes == 0.35.4 imageio-ffmpeg xformers == 0.0.16 - -extra-index-url https: // download.pytorch.org/whl/cu113\n","\n","# MMPose\n","%cd / content/mmpose\n","!python3 - m pip install torch torchvision torchaudio - -index-url https: // download.pytorch.org/whl/cu118\n","# install MMEngine, MMCV and MMDetection using MIM\n","!python3 - m pip install - U openmim\n","!mim install mmengine\n","!mim install \"mmcv>=2.0.0\"\n","!mim install \"mmdet>=3.0.0\"\n"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º Data Exploration"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#@title  US T13-4 Load Video\n","import ipywidgets as widgets\n","import os, cv2\n","from os import listdir\n","from google.colab.patches import cv2_imshow\n","from IPython.display import  HTML\n","from base64 import b64encode\n","\n","# variables\n","data_url = None\n","vid_directory = \"./ict3104-team13-2023/videos\"\n","vid_list = []\n","\n","# store video names in list\n","for files in os.listdir(vid_directory):\n","  if files[0] != \".\":\n","    vid_list.append(files)\n","\n","# show vid name in list as dropdown\n","dropdown = widgets.Dropdown(options=vid_list, value=None)\n","\n","# UI\n","button = widgets.Button(description=\"Enter\")\n","output = widgets.Output()\n","display(dropdown, button, output)\n","\n","# UI functions\n","def on_button_clicked(b):\n","    with output:\n","        mp4 = open(vid_directory+'/'+dropdown.value,'rb').read()\n","        data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","        if mp4 and data_url:\n","          display(HTML(\"\"\"\n","                  <video controls>\n","                        <source src=\"%s\" type=\"video/mp4\">\n","                  </video>\n","                  \"\"\" % data_url))\n","        else:\n","          print(\"error opening vid file\")\n","\n","\n","button.on_click(on_button_clicked)"]},{"cell_type":"markdown","metadata":{"id":"Kbx46ZU6znrs"},"source":["# ðŸ•ºðŸ•ºðŸ•º Inference"]},{"cell_type":"markdown","metadata":{"id":"6GW8-Xz8zwnE"},"source":["Due to memory of GPU, we recommend set video_length=8 in ./config/pose_sample.yaml for running successfully. \n","\n","Meanwhile, we should keep the skeleton frame length(./followyourpose/pipelines/pipeline_followyourpose.py:422 ) equal with video_length"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%cd /content/FollowYourPose\n","!pwd\n","!TORCH_DISTRIBUTED_DEBUG=DETAIL accelerate launch txt2video.py --config=\"configs/pose_sample.yaml\"  --skeleton_path=\"./pose_example/vis_ikun_pose2.mov\""]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#@title  User Story T13-6\n","import ipywidgets as widgets\n","import os, cv2\n","import subprocess\n","import yaml\n","from os import listdir\n","from google.colab.patches import cv2_imshow\n","from IPython.display import HTML, clear_output\n","from base64 import b64encode\n","\n","\n","# Define and Instantiate variables\n","charades_data_url = None\n","charades_video_path = \"./charades\"\n","charades_video_list = []\n","chosen_charades_video = None\n","\n","# Store names of charades video in a list\n","for file in os.listdir(charades_video_path):\n","  charades_video_list.append(file)\n","\n","# Show input to accept user prompt\n","prompt_input = widgets.Text(\n","    value='',  # Initial value\n","    placeholder='Enter prompt...',  # Placeholder text\n","    description='Prompt Input: ',  # Label for the input\n",")\n","\n","# Add names of charades video as dropdown options\n","charades_videos_dropdown = widgets.Dropdown(options=charades_video_list, value=None)\n","\n","# UI to show after running this cell\n","choose_charades_video_button = widgets.Button(description=\"Choose Video\")\n","chosen_video_output = widgets.Output()\n","\n","# Display all UI\n","display(prompt_input, charades_videos_dropdown, choose_charades_video_button, chosen_video_output)\n","\n","# method to add user's prompt into pose_sample.yaml\n","def insert_prompt_input_into_config(prompt):\n","\n","  # Load the YAML file\n","  with open('./configs/pose_sample.yaml', 'r') as file:\n","      config = yaml.safe_load(file)\n","\n","  # Access the 'prompts' section\n","  config['validation_data']['prompts'] = [prompt]\n","\n","\n","  # Save the modified configuration back to the file\n","  with open('./configs/pose_sample.yaml', 'w') as file:\n","      yaml.dump(config, file, default_flow_style=False)\n","\n","def generate_gif():\n","  # Change directory to /content/ict3104-team13-2023\n","  os.chdir('/content/ict3104-team13-2023')\n","\n","  # Print the current working directory\n","  print(os.getcwd())\n","\n","  # Set the TORCH_DISTRIBUTED_DEBUG environment variable and launch txt2video.py\n","  subprocess.run(['accelerate', 'launch', 'txt2video.py', '--config=configs/pose_sample.yaml', '--skeleton_path=./pose_example/vis_ikun_pose2.mov'])\n","\n","#\n","def set_charades_video_variables(charades_video_name):\n","  if charades_video_name is not None:\n","    # print(\"Have something\")\n","    pass\n","  with chosen_video_output:\n","        charades_mp4 = open(charades_video_path +'/'+ charades_video_name,'rb').read()\n","        charades_data_url = \"data:video/mp4;base64,\" + b64encode(charades_mp4).decode()\n","        if charades_mp4 and charades_data_url:\n","          video_html = f'<video controls><source src=\"{charades_data_url}\" type=\"video/mp4\"></video>'\n","          # Clear previous output\n","          clear_output()\n","          display(HTML(video_html))\n","        else:\n","          print(\"Cannot open chosen charades video\")\n","\n","# OnClick function for 'Choose Video' button\n","def on_choose_charades_video_button_clicked(b):\n","    pass\n","\n","# OnChange function for dropdown\n","def on_charades_videos_dropdown_change(change):\n","    if change['name'] == 'value' and change['new']:\n","        chosen_charades_video = change['new']\n","        selected_option = change['new']\n","        # print(f\"Selected option: {selected_option}\")\n","        set_charades_video_variables(selected_option)\n","\n","# On Prompt Input 'enter' key press\n","def on_prompt_input_enter_pressed(change):\n","      # print(\"Enter pressed with text:\", prompt_input.value)\n","      insert_prompt_input_into_config(prompt_input.value)\n","      generate_gif()\n","\n","# Attach event functions to UI\n","prompt_input.on_submit(on_prompt_input_enter_pressed)\n","charades_videos_dropdown.observe(on_charades_videos_dropdown_change, names='value')\n","choose_charades_video_button.on_click(on_choose_charades_video_button_clicked)"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º Testing"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"m-sw8eRt2fFa"},"source":["# ðŸ’ƒðŸ’ƒðŸ’ƒ The videos are output into ./output/samples"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOyNNhRT8BBHJeqGAp6TaSp","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
