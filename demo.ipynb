{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZI-7IKtJYIIf"},"source":["\n","# ðŸ•ºðŸ•ºðŸ•º Follow Your Pose ðŸ’ƒðŸ’ƒðŸ’ƒ: \n","# Pose-Guided Text-to-Video Generation using Pose-Free Videos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1680855034941,"user":{"displayName":"yue ma","userId":"10565880864345925493"},"user_tz":-480},"id":"GPBJ9ZPNWofP","outputId":"08c669fd-6983-48ab-805f-31878714772c","vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@markdown Check type of GPU and VRAM available.\n","!nvidia-smi - -query-gpu = name, memory.total, memory.free - -format = csv, noheader\n","#make sure you are using Tesla T4, 15360 MiB, 15101 MiB\n"]},{"cell_type":"markdown","metadata":{"id":"JGTUagmtwwxo"},"source":["# ðŸ•ºðŸ•ºðŸ•º Install Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21760,"status":"ok","timestamp":1680855062851,"user":{"displayName":"yue ma","userId":"10565880864345925493"},"user_tz":-480},"id":"JmWCIBSnZP4l","outputId":"7cbd0308-8e11-4140-8bff-58d9368d4a13","vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["# @title  Environment Setup\n","!apt-get update\n","!apt install software-properties-common\n","!sudo dpkg --remove --force-remove-reinstreq python3-pip python3-setuptools python3-wheel\n","!apt-get install python3-pip\n","\n","!git clone https: // github.com/jiaxinlarhh/ict3104-team13-2023.git\n","\n","!git clone https: // github.com/open-mmlab/mmpose.git\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["# @title  Setup FollowYourPose & MMPose\n","\n","# FollowYourPose\n","!cd / content/ict3104-team13-2023\n","!export PYTHONPATH = /content/ict3104-team13-2023: $PYTHONPATH\n","!python - m pip install - q - U - -pre triton\n","!apt update\n","!python - m pip install - q diffusers == 0.11.1 torch == 1.13.1 transformers == 4.26.0 bitsandbytes == 0.35.4 imageio-ffmpeg xformers == 0.0.16 - -extra-index-url https: // download.pytorch.org/whl/cu113\n","\n","# MMPose\n","%cd / content/mmpose\n","!python3 - m pip install torch torchvision torchaudio - -index-url https: // download.pytorch.org/whl/cu118\n","# install MMEngine, MMCV and MMDetection using MIM\n","!python3 - m pip install - U openmim\n","!mim install mmengine\n","!mim install \"mmcv>=2.0.0\"\n","!mim install \"mmdet>=3.0.0\"\n"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º Data Exploration"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@title US T13-3 Input files subfolders\n","\n","import os\n","\n","main_folder = '/content/ict3104-team13-2023/data_folder'\n","\n","if not os.path.exists(main_folder):\n","    os.mkdir(main_folder)\n","\n","subfolders = ['stickman', 'others']\n","\n","for subfolder in subfolders:\n","    subfolder_path = os.path.join(main_folder, subfolder)\n","\n","    if not os.path.exists(subfolder_path):\n","        os.mkdir(subfolder_path)\n","        print(f\"Created subfolder '{subfolder_path}'\")"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@title  US T13-4 Load Video\n","import ipywidgets as widgets\n","import os, cv2\n","from os import listdir\n","from google.colab.patches import cv2_imshow\n","from IPython.display import  HTML\n","from base64 import b64encode\n","\n","# variables\n","data_url = None\n","vid_directory = \"./ict3104-team13-2023/videos\"\n","vid_list = []\n","\n","# store video names in list\n","for files in os.listdir(vid_directory):\n","  if files[0] != \".\":\n","    vid_list.append(files)\n","\n","# show vid name in list as dropdown\n","dropdown = widgets.Dropdown(options=vid_list, value=None)\n","\n","# UI\n","button = widgets.Button(description=\"Enter\")\n","output = widgets.Output()\n","display(dropdown, button, output)\n","\n","# UI functions\n","def on_button_clicked(b):\n","    with output:\n","        mp4 = open(vid_directory+'/'+dropdown.value,'rb').read()\n","        data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","        if mp4 and data_url:\n","          display(HTML(\"\"\"\n","                  <video controls>\n","                        <source src=\"%s\" type=\"video/mp4\">\n","                  </video>\n","                  \"\"\" % data_url))\n","        else:\n","          print(\"error opening vid file\")\n","\n","\n","button.on_click(on_button_clicked)"]},{"cell_type":"markdown","metadata":{"id":"Kbx46ZU6znrs"},"source":["# ðŸ•ºðŸ•ºðŸ•º Inference"]},{"cell_type":"markdown","metadata":{"id":"6GW8-Xz8zwnE"},"source":["Due to memory of GPU, we recommend set video_length=8 in ./config/pose_sample.yaml for running successfully. \n","\n","Meanwhile, we should keep the skeleton frame length(./followyourpose/pipelines/pipeline_followyourpose.py:422 ) equal with video_length"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["%cd /content/FollowYourPose\n","!pwd\n","!TORCH_DISTRIBUTED_DEBUG=DETAIL accelerate launch txt2video.py --config=\"configs/pose_sample.yaml\"  --skeleton_path=\"./pose_example/vis_ikun_pose2.mov\""]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["# @title US T13-7 Inference videos with captions\n","\n","from moviepy.editor import VideoFileClip, clips_array\n","import os\n","from moviepy.editor import VideoFileClip\n","from PIL import Image, ImageSequence\n","from IPython.display import HTML, display, Image\n","\n","\n","# combine the inference video (stickman) with the video from charade into a GIF for display later\n","def combine_and_create_gif(mov_path, mp4_path, output_gif_path):\n","    # Loading the vid\n","    mov_video = VideoFileClip(mov_path)\n","    mp4_video = VideoFileClip(mp4_path)\n","\n","    width1, height1 = mov_video.size\n","    width2, height2 = mp4_video.size\n","\n","    min_width = min(width1, width2)\n","    min_height = min(height1, height2)\n","\n","    # Resize both vid to have same width and height\n","    mov_video = mov_video.resize((min_width, min_height))\n","    mp4_video = mp4_video.resize((min_width, min_height))\n","\n","    # Combine the vid side by side\n","    result = clips_array([[mov_video, mp4_video]])\n","\n","    # Write as GIF for display\n","    result.write_gif(output_gif_path, fps=10)\n","\n","# Resize the GIF to reduce resources\n","def resize_gif(input_path, output_path, new_width, new_height):\n","    # Open the GIF file\n","    img = Image.open(input_path)\n","\n","    # Create an empty list to store resized frames\n","    resized_frames = []\n","\n","    # Loop through the frames in the GIF\n","    for frame in ImageSequence.Iterator(img):\n","        # Resize each frame to the specified dimension\n","        resized_frame = frame.resize((new_width, new_height), Image.ANTIALIAS)\n","        resized_frames.append(resized_frame)\n","\n","    # Save the resized frames as a new GIF\n","    resized_frames[0].save(output_path, save_all=True, append_images=resized_frames[1:], duration=img.info['duration'], loop=0)\n","\n","def display_result(gif_path, caption):\n","\n","    # Display the GIF\n","\n","    display(Image(filename=gif_path))\n","    display(HTML(f'<p style=\"text-align:center; font-size:16px;\">{caption}</p>'))\n","\n","# testing:\n","mov_path = './pose_example/vis_ikun_pose2.mov'\n","mp4_path = './charades/0RJKT.mp4'\n","gif_path = './output/output.gif'\n","caption = 'test'\n","\n","\n","# to resize the gif (reduce resources for google colab)\n","new_width = 320\n","new_height = 240\n","\n","combine_and_create_gif(mov_path, mp4_path, gif_path)\n","resize_gif(gif_path, gif_path, new_width, new_height)\n","display_result(gif_path, caption)"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º Training"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@title  User Story T13-8: Select subfolder from dataset folder\n","import ipywidgets as widgets\n","import os, cv2\n","from os import listdir\n","from ipywidgets import Dropdown, interact\n","\n","data_directory = \"./dataset_folder\"\n","directory_dict = {}\n","\n","# get subfolders as key and list of files as value in dict\n","for root, subfolders, files in os.walk(data_directory):\n","    # Skip the root directory itself\n","    if root == data_directory:\n","        continue\n","\n","    subfolder_name = os.path.relpath(root, data_directory)\n","\n","    if \".ipynb\" in subfolder_name:\n","      continue\n","    # Create a list of file names in the subfolder\n","    file_names = [file for file in files]\n","    # Add the subfolder and its file names to the dictionary\n","    directory_dict[subfolder_name] = file_names\n","#print(directory_dict)\n","\n","\n","# dropdown UI\n","subfolder_choices = Dropdown(options =directory_dict.keys())\n","subfolder_files = Dropdown()\n","button = widgets.Button(description=\"Select dataset\")\n","\n","\n","@interact(subfolder = subfolder_choices, dataset = subfolder_files)\n","def print_city(subfolder, dataset):\n","    subfolder_files.options = directory_dict[subfolder]\n","\n","# UI\n","display(button)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@title  User Story T13-6\n","import ipywidgets as widgets\n","import os, cv2\n","import subprocess\n","import yaml\n","from os import listdir\n","from google.colab.patches import cv2_imshow\n","from IPython.display import HTML, clear_output\n","from base64 import b64encode\n","\n","\n","# Define and Instantiate variables\n","charades_data_url = None\n","charades_video_path = \"./charades\"\n","charades_video_list = []\n","chosen_charades_video = None\n","\n","# Store names of charades video in a list\n","for file in os.listdir(charades_video_path):\n","  charades_video_list.append(file)\n","\n","# Show input to accept user prompt\n","prompt_input = widgets.Text(\n","    value='',  # Initial value\n","    placeholder='Enter prompt...',  # Placeholder text\n","    description='Prompt Input: ',  # Label for the input\n",")\n","\n","# Add names of charades video as dropdown options\n","charades_videos_dropdown = widgets.Dropdown(options=charades_video_list, value=None)\n","\n","# UI to show after running this cell\n","choose_charades_video_button = widgets.Button(description=\"Choose Video\")\n","chosen_video_output = widgets.Output()\n","\n","# Display all UI\n","display(prompt_input, charades_videos_dropdown, choose_charades_video_button, chosen_video_output)\n","\n","# method to add user's prompt into pose_sample.yaml\n","def insert_prompt_input_into_config(prompt):\n","\n","  # Load the YAML file\n","  with open('./configs/pose_sample.yaml', 'r') as file:\n","      config = yaml.safe_load(file)\n","\n","  # Access the 'prompts' section\n","  config['validation_data']['prompts'] = [prompt]\n","\n","\n","  # Save the modified configuration back to the file\n","  with open('./configs/pose_sample.yaml', 'w') as file:\n","      yaml.dump(config, file, default_flow_style=False)\n","\n","def generate_gif():\n","  # Change directory to /content/ict3104-team13-2023\n","  os.chdir('/content/ict3104-team13-2023')\n","\n","  # Print the current working directory\n","  print(os.getcwd())\n","\n","  # Set the TORCH_DISTRIBUTED_DEBUG environment variable and launch txt2video.py\n","  subprocess.run(['accelerate', 'launch', 'txt2video.py', '--config=configs/pose_sample.yaml', '--skeleton_path=./pose_example/vis_ikun_pose2.mov'])\n","\n","#\n","def set_charades_video_variables(charades_video_name):\n","  if charades_video_name is not None:\n","    # print(\"Have something\")\n","    pass\n","  with chosen_video_output:\n","        charades_mp4 = open(charades_video_path +'/'+ charades_video_name,'rb').read()\n","        charades_data_url = \"data:video/mp4;base64,\" + b64encode(charades_mp4).decode()\n","        if charades_mp4 and charades_data_url:\n","          video_html = f'<video controls><source src=\"{charades_data_url}\" type=\"video/mp4\"></video>'\n","          # Clear previous output\n","          clear_output()\n","          display(HTML(video_html))\n","        else:\n","          print(\"Cannot open chosen charades video\")\n","\n","# OnClick function for 'Choose Video' button\n","def on_choose_charades_video_button_clicked(b):\n","    pass\n","\n","# OnChange function for dropdown\n","def on_charades_videos_dropdown_change(change):\n","    if change['name'] == 'value' and change['new']:\n","        chosen_charades_video = change['new']\n","        selected_option = change['new']\n","        # print(f\"Selected option: {selected_option}\")\n","        set_charades_video_variables(selected_option)\n","\n","# On Prompt Input 'enter' key press\n","def on_prompt_input_enter_pressed(change):\n","      # print(\"Enter pressed with text:\", prompt_input.value)\n","      insert_prompt_input_into_config(prompt_input.value)\n","      generate_gif()\n","\n","# Attach event functions to UI\n","prompt_input.on_submit(on_prompt_input_enter_pressed)\n","charades_videos_dropdown.observe(on_charades_videos_dropdown_change, names='value')\n","choose_charades_video_button.on_click(on_choose_charades_video_button_clicked)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title  User Story T13-10\n","import ipywidgets as widgets\n","from IPython.display import display\n","\n","model_name_input = widgets.Text(\n","    placeholder='Enter Model Name',\n","    description='Model Name:',\n",")\n","\n","enter_button = widgets.Button(\n","    description='Enter',\n","    button_style='primary', \n",")\n","\n","# add to the model when its out\n","def handle_enter_button_click(b):\n","    model_name = model_name_input.value\n","    print(f'Done')\n","    \n","enter_button.on_click(handle_enter_button_click)\n","display(model_name_input, enter_button)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"polyglot-notebook"}},"outputs":[],"source":["#@title  User Story T13-11\n","import ipywidgets as widgets\n","# Give user preset sample size with default value of 16 \n","# batch selection\n","batch_size_options = widgets.ToggleButtons(\n","    options=[('Small', 16), ('Medium', 64), ('Large', 128)],\n","    description='Batch Size:',\n","    disabled=False,\n","    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n","    tooltips=['Batch size of 16', 'Batch size of 64', 'Batch size of 128'],\n","#     icons=['check'] * 3\n",")\n","# epoch selection\n","epoch_options = widgets.ToggleButtons(\n","    options=[('Quick', 10), ('Standard', 50), ('Comprehensize', 100)],\n","    description='Epoch value:',\n","    disabled=False,\n","    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n","    tooltips=['Epoch value of 10', 'Epoch value of 50', 'Epoch value of 100'],\n","#     icons=['check'] * 3\n",")\n","confirm_button = widgets.Button(description=\"Apply Configurations\")\n","\n","\n","# Show UIs\n","display(batch_size_options, epoch_options, confirm_button)\n","\n","# values should be used in T13-12\n","# configurations - 1. epoch (epoch_options.value) 2. batch size(batch_size_options.value)\n","def configurations_confirmed(b):\n","  pass\n","\n","# Attach event functions to UI\n","confirm_button.on_click(configurations_confirmed)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º Testing"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ•ºðŸ•ºðŸ•º MMPose"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title Environment Setup\n","!update-alternatives --install /usr/local/bin/python3 python3 /usr/bin/python3.8 2\n","!update-alternatives --install /usr/local/bin/python3 python3 /usr/bin/python3.9 1\n","!python --version\n","!apt-get update\n","!apt install software-properties-common\n","!sudo dpkg --remove --force-remove-reinstreq python3-pip python3-setuptools python3-wheel\n","!apt-get install python3-pip\n","\n","%cd /content\n","\n","# forked michael's mmpose because project needed to change some of the mmpose code\n","!git clone https://github.com/micdiary/mmpose.git\n","\n","#MMPose\n","%cd /content/mmpose\n","!python3 -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","# install MMEngine, MMCV and MMDetection using MIM\n","!python3 -m pip install -U openmim\n","!mim install mmengine\n","!mim install \"mmcv>=2.0.0\"\n","!mim install \"mmdet>=3.0.0\"\n","\n","!python3 -m pip install -r requirements.txt\n","!python3 -m pip install -v -e .\n","\n","!python3 -m pip install setuptools==68.1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title Check MMpose\n","\n","%cd /content/mmpose/\n","\n","# Check Pytorch installation\n","import torch, torchvision\n","\n","print('torch version:', torch.__version__, torch.cuda.is_available())\n","print('torchvision version:', torchvision.__version__)\n","\n","# Check MMPose installation\n","import mmpose\n","\n","print('mmpose version:', mmpose.__version__)\n","\n","# Check mmcv installation\n","from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n","\n","print('cuda version:', get_compiling_cuda_version())\n","print('compiler information:', get_compiler_version())"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#@title Inference with MMPOSE\n","import os\n","\n","%cd /content/mmpose\n","\n","charades_video_path = \"/content/ict3104-team13-2023/charades/\"\n","\n","# List all the MP4 files in the specified directory\n","mp4_files = [f for f in os.listdir(charades_video_path) if f.endswith('.mp4')]\n","\n","\n","# Iterate through the MP4 files and run the script for each one\n","for mp4_file in mp4_files:\n","    input_path = os.path.join(charades_video_path, mp4_file)\n","    output_folder = f\"/content/ict3104-team13-2023/data_folder/stickman/\"\n","\n","    !python demo/topdown_demo_with_mmdet.py \\\n","    demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py \\\n","    https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n","    configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-256x192.py \\\n","    https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth \\\n","    --input {input_path} \\\n","    --output-root {output_folder}"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOyNNhRT8BBHJeqGAp6TaSp","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
